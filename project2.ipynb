{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8397fdda",
   "metadata": {},
   "source": [
    "# Ø¨Ù‡ Ù†Ø§Ù… Ø®Ø¯Ø§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81215f",
   "metadata": {},
   "source": [
    "# ÙØ§Ø² 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "259fd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49cd300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 217/217 [00:00<00:00, 301.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§Ø² Ø§ÙˆÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ù¾Ù„Ø§Ú©â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø¯Ø± Ù¾ÙˆØ´Ù‡ 'output_phase1' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def parse_annotation(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    plates = []\n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text\n",
    "        if name.lower() == 'vehicle plate':\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = int(bndbox.find('xmin').text)\n",
    "            ymin = int(bndbox.find('ymin').text)\n",
    "            xmax = int(bndbox.find('xmax').text)\n",
    "            ymax = int(bndbox.find('ymax').text)\n",
    "            plates.append((xmin, ymin, xmax, ymax))\n",
    "    \n",
    "    return plates\n",
    "\n",
    "def extract_plates(image_path, annotation_path, output_path):\n",
    "    # Ø®ÙˆØ§Ù†Ø¯Ù† ØªØµÙˆÛŒØ±\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ØªØµÙˆÛŒØ±: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Ø®ÙˆØ§Ù†Ø¯Ù† Ø¢Ù†ÙˆØªÛŒØ´Ù†â€ŒÙ‡Ø§\n",
    "    plates = parse_annotation(annotation_path)\n",
    "    if not plates:\n",
    "        print(f\"Ù‡ÛŒÚ† Ù¾Ù„Ø§Ú©ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ Ø¢Ù†ÙˆØªÛŒØ´Ù† ÛŒØ§ÙØª Ù†Ø´Ø¯: {annotation_path}\")\n",
    "        return\n",
    "    \n",
    "    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù‡Ø± Ù¾Ù„Ø§Ú©\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    for i, (xmin, ymin, xmax, ymax) in enumerate(plates):\n",
    "        plate_img = image[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        # Ø°Ø®ÛŒØ±Ù‡ Ù¾Ù„Ø§Ú© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡\n",
    "        output_file = os.path.join(output_path, f\"{base_name}.png\")\n",
    "        cv2.imwrite(output_file, plate_img)\n",
    "\n",
    "def process_dataset(base_dir, output_dir):\n",
    "    # Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ\n",
    "    images_dir = os.path.join(base_dir, \"Vehicle Plates\", \"Vehicle Plates\")\n",
    "    annotations_dir = os.path.join(base_dir, \"Vehicle Plates annotations\", \"Vehicle Plates annotations\")\n",
    "    \n",
    "    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§\n",
    "    if not os.path.exists(images_dir):\n",
    "        print(f\"Ù¾ÙˆØ´Ù‡ ØªØµØ§ÙˆÛŒØ± ÛŒØ§ÙØª Ù†Ø´Ø¯: {images_dir}\")\n",
    "        return\n",
    "    if not os.path.exists(annotations_dir):\n",
    "        print(f\"Ù¾ÙˆØ´Ù‡ Ø¢Ù†ÙˆØªÛŒØ´Ù†â€ŒÙ‡Ø§ ÛŒØ§ÙØª Ù†Ø´Ø¯: {annotations_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªØµÙˆÛŒØ±\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø± ØªØµÙˆÛŒØ± Ø¨Ø§ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª\n",
    "    for img_file in tqdm(image_files, desc=\"Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±\"):\n",
    "        base_name = os.path.splitext(img_file)[0]\n",
    "        image_path = os.path.join(images_dir, img_file)\n",
    "        annotation_path = os.path.join(annotations_dir, f\"{base_name}.xml\")\n",
    "        \n",
    "        if os.path.exists(annotation_path):\n",
    "            extract_plates(image_path, annotation_path, output_dir)\n",
    "        else:\n",
    "            print(f\"ÙØ§ÛŒÙ„ Ø¢Ù†ÙˆØªÛŒØ´Ù† ÛŒØ§ÙØª Ù†Ø´Ø¯: {annotation_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "    base_dir = \"Plates2\"\n",
    "    output_dir = \"output_phase1\"\n",
    "    \n",
    "    # Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´\n",
    "    process_dataset(base_dir, output_dir)\n",
    "    \n",
    "    print(f\"Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§Ø² Ø§ÙˆÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ù¾Ù„Ø§Ú©â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø¯Ø± Ù¾ÙˆØ´Ù‡ '{output_dir}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c34b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "029a3767",
   "metadata": {},
   "source": [
    "# ÙØ§Ø² 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f5693a",
   "metadata": {},
   "source": [
    "### Ø¯Ø±Ø³Øª Ú©Ø±Ø¯Ù† Ú©Ø¬ÛŒ Ùˆ Ø³ÛŒØ§Ù‡ Ø³ÙÛŒØ¯ Ú©Ø±Ø¯Ù†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f24242e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ø§ØµÙ„Ø§Ø­ Ø²Ø§ÙˆÛŒÙ‡ Ø¨Ø§ ØªØ±Ú©ÛŒØ¨ minAreaRect + Hough Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_folder = 'output_phase1'\n",
    "output_folder = 'output_phase2'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "def angle_from_min_area_rect(thresh):\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    largest = max(contours, key=cv2.contourArea)\n",
    "    rect = cv2.minAreaRect(largest)\n",
    "    angle = rect[-1]\n",
    "    if angle < -45:\n",
    "        angle += 90\n",
    "    elif angle > 45:\n",
    "        angle -= 90\n",
    "    return angle\n",
    "\n",
    "def angle_from_hough(gray):\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, minLineLength=30, maxLineGap=10)\n",
    "    if lines is None:\n",
    "        return None\n",
    "    angles = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "        if -45 < angle < 45:\n",
    "            angles.append(angle)\n",
    "    if not angles:\n",
    "        return None\n",
    "    return np.median(angles)\n",
    "\n",
    "def correct_skew_combined(gray_image, angle_threshold=3):\n",
    "    # Preprocess\n",
    "    _, thresh = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    thresh = 255 - thresh\n",
    "\n",
    "    # Step 1: try minAreaRect\n",
    "    angle = angle_from_min_area_rect(thresh)\n",
    "\n",
    "    # Step 2: fallback to HoughLines if angle too small or None\n",
    "    if angle is None or abs(angle) < angle_threshold:\n",
    "        angle = angle_from_hough(gray_image)\n",
    "\n",
    "    # Ø§Ú¯Ø± Ù‡Ù…Ú†Ù†Ø§Ù† Ø²Ø§ÙˆÛŒÙ‡ Ù…Ø¹Ù†Ø§Ø¯Ø§Ø± Ù†Ø¨ÙˆØ¯ØŒ ØªØµÙˆÛŒØ± Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†\n",
    "    if angle is None or abs(angle) < angle_threshold:\n",
    "        return gray_image\n",
    "\n",
    "    # Rotate\n",
    "    (h, w) = gray_image.shape\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(gray_image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "# Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ù‡ ØªØµØ§ÙˆÛŒØ±\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "        path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        corrected = correct_skew_combined(gray)\n",
    "\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, corrected)\n",
    "\n",
    "print(\"âœ… Ø§ØµÙ„Ø§Ø­ Ø²Ø§ÙˆÛŒÙ‡ Ø¨Ø§ ØªØ±Ú©ÛŒØ¨ minAreaRect + Hough Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be0ea65",
   "metadata": {},
   "source": [
    "### Ú©Ø§Øª Ø¯Ø§Ø¯Ù† ÛŒÚ© Ù‡Ø´ØªÙ… Ø§ÙˆÙ„ Ù¾Ù„Ø§Ú©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95457256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙ…Ø§Ù… Ø´Ø¯.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "input_dir = 'output_phase2'\n",
    "output_dir = 'output_phase2.1'\n",
    "\n",
    "# Ø³Ø§Ø®Øª Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´Øª\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø± ØªØµÙˆÛŒØ± Ø¯Ø± Ù¾ÙˆØ´Ù‡ ÙˆØ±ÙˆØ¯ÛŒ\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tif')):\n",
    "        img_path = os.path.join(input_dir, filename)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Ø§Ø¨Ø¹Ø§Ø¯ ØªØµÙˆÛŒØ±\n",
    "        width, height = img.size\n",
    "\n",
    "        # Ø¹Ø±Ø¶ Ù‡Ø± ØªÚ©Ù‡\n",
    "        slice_width = width // 8\n",
    "\n",
    "        # Ø¨Ø±Ø´ ØªØµÙˆÛŒØ±: Ø­Ø°Ù ØªÛŒÚ©Ù‡ Ø§ÙˆÙ„ (Ø§Ø² x=0 ØªØ§ x=slice_width)\n",
    "        # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† Ø¨Ø®Ø´ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ (Ø§Ø² x=slice_width ØªØ§ x=width)\n",
    "        cropped_img = img.crop((slice_width, 0, width, height))\n",
    "\n",
    "        # Ø°Ø®ÛŒØ±Ù‡ ØªØµÙˆÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cropped_img.save(output_path)\n",
    "\n",
    "print(\"Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙ…Ø§Ù… Ø´Ø¯.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea3df5",
   "metadata": {},
   "source": [
    "### Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ú©Ø±Ø¯Ù† Ø¹Ú©Ø³ Ù‡Ø§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd13ae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ø¨Ø§ Ø­ÙØ¸ Ø¬Ø²Ø¦ÛŒØ§Øª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_folder = 'output_phase2.1'\n",
    "output_folder = 'output_phase2.2'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # 1. Ù†ÙˆÛŒØ²Ø²Ø¯Ø§ÛŒÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ± ØºÛŒØ±Ù…Ø­Ù„ÛŒ (Non-local Means)\n",
    "        denoised = cv2.fastNlMeansDenoising(img, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "        \n",
    "        # 2. Ø§ÙØ²Ø§ÛŒØ´ Ú©Ù†ØªØ±Ø§Ø³Øª Ø¨Ø§ CLAHE (Ø¨Ù‡ØªØ± Ø§Ø² Ø§Ú©ÙˆÙ„Ø§ÛŒØ²ÛŒØ´Ù† Ø³Ø§Ø¯Ù‡)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        contrast_enhanced = clahe.apply(denoised)\n",
    "        \n",
    "        # 3. ÙÛŒÙ„ØªØ± Ú¯ÙˆØ³ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ø±Ù… Ú©Ø±Ø¯Ù† (Ø¨Ø§ Ù‡Ø³ØªÙ‡ Ú©ÙˆÚ†Ú©ØªØ±)\n",
    "        blurred = cv2.GaussianBlur(contrast_enhanced, (3,3), 0)\n",
    "        \n",
    "        # 4. Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ ØªØ·Ø¨ÛŒÙ‚ÛŒ Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØªØ±\n",
    "        binary_img = cv2.adaptiveThreshold(\n",
    "            blurred,\n",
    "            255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY_INV,\n",
    "            11,  # Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ù„ÙˆÚ© - Ø¨Ø§ÛŒØ¯ Ú©ÙˆÚ†Ú©ØªØ± Ø¨Ø§Ø´Ø¯ Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ Ø¬Ø²Ø¦ÛŒØ§Øª\n",
    "            2    # Ù…Ù‚Ø¯Ø§Ø± Ø«Ø§Ø¨Øª - Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø³ÛŒØ§Ù‡ Ø´Ø¯Ù† Ù†ÙˆØ§Ø­ÛŒ Ø±ÙˆØ´Ù†\n",
    "        )\n",
    "        \n",
    "        # 5. Ù…ÙˆØ±ÙÙˆÙ„ÙˆÚ˜ÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ù†ÙˆÛŒØ²Ù‡Ø§ÛŒ Ú©ÙˆÚ†Ú©\n",
    "        kernel = np.ones((2,2), np.uint8)\n",
    "        processed = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Ù…Ø¹Ú©ÙˆØ³ Ú©Ø±Ø¯Ù† ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø´ØªÙ† Ù…ØªÙ† Ø³ÙÛŒØ¯ Ø±ÙˆÛŒ Ù¾Ø³ Ø²Ù…ÛŒÙ†Ù‡ Ø³ÛŒØ§Ù‡\n",
    "        final_img = cv2.bitwise_not(processed)\n",
    "        \n",
    "        # Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, final_img)\n",
    "\n",
    "print(\"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ø¨Ø§ Ø­ÙØ¸ Ø¬Ø²Ø¦ÛŒØ§Øª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e54b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§ Ø­ÙØ¸ Ø­Ø¯Ø§Ú©Ø«Ø± Ú©ÛŒÙÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_folder = 'output_phase2.1'\n",
    "output_folder = 'output_phase2.2'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # 1. Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø§ Ø­ÙØ¸ Ø¬Ø²Ø¦ÛŒØ§Øª\n",
    "        denoised = cv2.fastNlMeansDenoising(img, h=5, templateWindowSize=7, searchWindowSize=21)\n",
    "        \n",
    "        # 2. Ø§ÙØ²Ø§ÛŒØ´ Ú©Ù†ØªØ±Ø§Ø³Øª Ù‡ÙˆØ´Ù…Ù†Ø¯\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(12,12))\n",
    "        contrast_enhanced = clahe.apply(denoised)\n",
    "        \n",
    "        # 3. Ø¨Ù‡Ø¨ÙˆØ¯ Ù„Ø¨Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ ÙÛŒÙ„ØªØ± ÙˆÛŒÚ˜Ù‡\n",
    "        blurred = cv2.bilateralFilter(contrast_enhanced, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "        \n",
    "        # 4. Ø±ÙˆØ´ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ\n",
    "        # Ù…Ø±Ø­Ù„Ù‡ Ø§ÙˆÙ„: Adaptive Threshold\n",
    "        binary_adaptive = cv2.adaptiveThreshold(\n",
    "            blurred,\n",
    "            255,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY_INV,\n",
    "            blockSize=9,\n",
    "            C=2\n",
    "        )\n",
    "        \n",
    "        # Ù…Ø±Ø­Ù„Ù‡ Ø¯ÙˆÙ…: Otsu Threshold\n",
    "        _, binary_otsu = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Ù…Ø±Ø­Ù„Ù‡ Ø³ÙˆÙ…: ØªØ±Ú©ÛŒØ¨ Ø¨Ø§ ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ\n",
    "        combined = cv2.addWeighted(binary_adaptive, 0.7, binary_otsu, 0.3, 0)\n",
    "        \n",
    "        # 5. Ø¨Ù‡Ø¨ÙˆØ¯ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ ØªÚ©Ù†ÛŒÚ© Super-Resolution (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\n",
    "        # Ø§Ú¯Ø± opencv Ø¨Ø§ contrib Ù†ØµØ¨ Ø¨Ø§Ø´Ø¯:\n",
    "        # super_res = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "        # super_res.readModel('EDSR_x4.pb')\n",
    "        # super_res.setModel('edsr', 4)\n",
    "        # final_img = super_res.upsample(combined)\n",
    "        \n",
    "        # 6. Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, cv2.bitwise_not(combined))\n",
    "\n",
    "print(\"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§ Ø­ÙØ¸ Ø­Ø¯Ø§Ú©Ø«Ø± Ú©ÛŒÙÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ef098",
   "metadata": {},
   "source": [
    "### Ø¯Ø± Ø§ÙˆØ±Ø¯Ù† Ú©Ø§Ø±Ø§Ú©ØªØ± Ù‡Ø§ÛŒ Ù‡Ø± Ø¹Ú©Ø³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "657e64f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 1.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 10.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 100.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 101.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 102.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 103.png: 2 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 104.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 105.png: 10 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 106.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 107.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 108.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 109.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 11.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 110.png: 10 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 111.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 112.png: 3 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 113.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 114.png: 11 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 115.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 116.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 117.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 118.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 119.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 12.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 120.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 121.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 122.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 123.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 124.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 125.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 126.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 127.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 128.png: 1 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 129.png: 3 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 13.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 130.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 131.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 132.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 133.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 134.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 135.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 136.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 137.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 138.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 139.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 14.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 140.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 141.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 142.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 143.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 144.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 145.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 146.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 147.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 148.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 149.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 15.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 150.png: 3 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 151.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 152.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 153.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 154.png: 3 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 155.png: 2 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 156.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 157.png: 2 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 158.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 159.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 16.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 160.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 161.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 162.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 163.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 164.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 165.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 166.png: 3 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 167.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 168.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 169.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 17.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 170.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 171.png: 2 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 172.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 173.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 174.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 175.png: 10 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 176.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 177.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 178.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 179.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 18.png: 3 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 180.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 181.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 182.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 183.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 184.png: 1 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 185.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 186.png: 3 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 187.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 188.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 189.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 19.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 190.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 191.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 192.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 193.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 194.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 195.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 196.png: 2 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 197.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 198.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 199.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 2.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 20.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 200.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 201.png: 1 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 202.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 203.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 204.png: 0 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 205.png: 10 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 206.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 207.png: 3 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 208.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 209.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 21.png: 10 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 210.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 211.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 212.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 213.png: 10 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 214.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 215.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 216.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 217.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 22.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 23.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 24.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 25.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 26.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 27.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 28.png: 10 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 29.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 3.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 30.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 31.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 32.png: 11 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 33.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 34.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 35.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 36.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 37.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 38.png: 10 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 39.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 4.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 40.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 41.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 42.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 43.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 44.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 45.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 46.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 47.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 48.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 49.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 5.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 50.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 51.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 52.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 53.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 54.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 55.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 56.png: 1 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 57.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 58.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 59.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 6.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 60.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 61.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 62.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 63.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 64.png: 3 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 65.png: 3 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 66.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 67.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 68.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 69.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 7.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 70.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 71.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 72.png: 12 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 73.png: 10 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 74.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 75.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 76.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 77.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 78.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 79.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 8.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 80.png: 10 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 81.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 82.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 83.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 84.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 85.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 86.png: 9 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 87.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 88.png: 12 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 89.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 9.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 90.png: 3 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 91.png: 2 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 92.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 93.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 94.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 95.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 96.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 97.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 98.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 99.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "ğŸ¯ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯ - Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ Ùˆ ØªØ¹Ø¯Ø§Ø¯ Ø¨ÛŒØ´ØªØ±.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_folder = \"output_phase2.2\"\n",
    "output_folder = \"output_phase2.3\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(input_folder, filename)\n",
    "    img_original = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img_original is None:\n",
    "        print(f\"â›” Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† ØªØµÙˆÛŒØ± {filename} Ø±Ø§ Ø®ÙˆØ§Ù†Ø¯.\")\n",
    "        continue\n",
    "\n",
    "    # Ø¨Ø²Ø±Ú¯Ù†Ù…Ø§ÛŒÛŒ Ã—3 Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ Ø¬Ø²Ø¦ÛŒØ§Øª\n",
    "    scale = 3\n",
    "    img_highres = cv2.resize(img_original, (img_original.shape[1]*scale, img_original.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # ÙÛŒÙ„ØªØ± Ú¯ÙˆØ³ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù†ÙˆÛŒØ²\n",
    "    img_blur = cv2.GaussianBlur(img_highres, (3, 3), 0)\n",
    "\n",
    "    # Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ ØªØ·Ø¨ÛŒÙ‚ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ù†ÙˆØ±Ù‡Ø§ÛŒ ØºÛŒØ± ÛŒÚ©Ù†ÙˆØ§Ø®Øª\n",
    "    img_bin = cv2.adaptiveThreshold(\n",
    "        img_blur, 255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        15, 8\n",
    "    )\n",
    "\n",
    "    # Ø­Ø°Ù Ù†ÙˆÛŒØ²Ù‡Ø§ÛŒ Ø±ÛŒØ²\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    img_bin = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªÙ…Ø§Ù… Ú©Ø§Ù†ØªÙˆØ±Ù‡Ø§ (Ù†Ù‡ ÙÙ‚Ø· Ø®Ø§Ø±Ø¬ÛŒ)\n",
    "    contours, _ = cv2.findContours(img_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "\n",
    "    if len(bounding_boxes) == 0:\n",
    "        continue\n",
    "\n",
    "    heights = [h for (_, _, _, h) in bounding_boxes]\n",
    "    widths = [w for (_, _, w, _) in bounding_boxes]\n",
    "    mean_height = np.mean(heights)\n",
    "    mean_width = np.mean(widths)\n",
    "\n",
    "    filtered_boxes = []\n",
    "    for x, y, w, h in bounding_boxes:\n",
    "        aspect_ratio = h / float(w + 1e-5)\n",
    "        if w < 6 or h < 15:\n",
    "            continue\n",
    "        if h < 0.4 * mean_height or h > 2.2 * mean_height:\n",
    "            continue\n",
    "        if w > 3.0 * mean_width:\n",
    "            continue\n",
    "        if not (0.5 < aspect_ratio < 7.0):\n",
    "            continue\n",
    "\n",
    "        # Ø¨Ø±Ø±Ø³ÛŒ Ú†Ú¯Ø§Ù„ÛŒ Ù¾ÛŒÚ©Ø³Ù„ Ø³ÙÛŒØ¯ (Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ù†ÙˆÛŒØ²)\n",
    "        roi = img_bin[y:y + h, x:x + w]\n",
    "        white_ratio = np.sum(roi == 255) / (roi.shape[0] * roi.shape[1])\n",
    "        if white_ratio < 0.05 or white_ratio > 0.9:\n",
    "            continue\n",
    "\n",
    "        filtered_boxes.append((x, y, w, h))\n",
    "\n",
    "    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø§Ø² Ú†Ù¾ Ø¨Ù‡ Ø±Ø§Ø³Øª\n",
    "    filtered_boxes = sorted(filtered_boxes, key=lambda b: b[0])\n",
    "    pad = 6\n",
    "    count = 0\n",
    "\n",
    "    for i, (x, y, w, h) in enumerate(filtered_boxes):\n",
    "        x_new = max(x - pad, 0)\n",
    "        y_new = max(y - pad, 0)\n",
    "        w_new = min(w + 2 * pad, img_highres.shape[1] - x_new)\n",
    "        h_new = min(h + 2 * pad, img_highres.shape[0] - y_new)\n",
    "\n",
    "        char_img = img_highres[y_new:y_new + h_new, x_new:x_new + w_new]\n",
    "\n",
    "        # resize Ùˆ Ø´Ø§Ø±Ù¾â€ŒØ³Ø§Ø²ÛŒ\n",
    "        char_img_resized = cv2.resize(char_img, (64, 128), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        kernel_sharp = np.array([[0, -1, 0],\n",
    "                                 [-1, 5, -1],\n",
    "                                 [0, -1, 0]])\n",
    "        char_img_resized = cv2.filter2D(char_img_resized, -1, kernel_sharp)\n",
    "\n",
    "        out_name = f\"{os.path.splitext(filename)[0]}_char{count + 1}.png\"\n",
    "        cv2.imwrite(os.path.join(output_folder, out_name), char_img_resized)\n",
    "        count += 1\n",
    "\n",
    "    print(f\"âœ… {filename}: {count} Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n",
    "\n",
    "print(\"ğŸ¯ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯ - Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ Ùˆ ØªØ¹Ø¯Ø§Ø¯ Ø¨ÛŒØ´ØªØ±.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f62bb93",
   "metadata": {},
   "source": [
    "### ØªÙ†Ø¸ÛŒÙ… Ø³Ø§ÛŒØ² ØªØµØ§ÙˆÛŒØ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df9a3625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1464/1464 [00:00<00:00, 1732.57it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ù…Ø³ÛŒØ±Ù‡Ø§\n",
    "input_dir = 'output_phase2.3'\n",
    "output_dir = 'output_phase2.4'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def clean_and_center_image(img, size=(28, 28)):\n",
    "    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø®Ø§Ú©Ø³ØªØ±ÛŒ Ø§Ú¯Ø± Ø±Ù†Ú¯ÛŒ Ø¨ÙˆØ¯\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ú©Ø±Ø¯Ù† (Ù…ØªÙ† Ø³ÛŒØ§Ù‡ØŒ Ø²Ù…ÛŒÙ†Ù‡ Ø³ÙÛŒØ¯)\n",
    "    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Ø­Ø°Ù Ù†ÙˆÛŒØ² Ø¨Ø§ Morphology\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    clean = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¨Ø²Ø±Ú¯â€ŒØªØ±ÛŒÙ† Ú©Ø§Ù†ØªÙˆØ± (Ú©Ø§Ø±Ø§Ú©ØªØ± Ø§ØµÙ„ÛŒ)\n",
    "    contours, _ = cv2.findContours(clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return np.ones(size, dtype=np.uint8) * 255  # Ø¨Ø±Ú¯Ø±Ø¯ ØªØµÙˆÛŒØ± Ø³ÙÛŒØ¯ Ø®Ø§Ù„ÛŒ\n",
    "\n",
    "    # Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø²Ø±Ú¯â€ŒØªØ±ÛŒÙ† Ú©Ø§Ù†ØªÙˆØ±\n",
    "    main_contour = max(contours, key=cv2.contourArea)\n",
    "    mask = np.zeros_like(clean)\n",
    "    cv2.drawContours(mask, [main_contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    # ÙÙ‚Ø· Ú©Ø§Ø±Ø§Ú©ØªØ± Ø§ØµÙ„ÛŒ Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø´Ù‡\n",
    "    isolated = cv2.bitwise_and(clean, mask)\n",
    "\n",
    "    # Ú©Ø±Ø§Ù¾ Ø¨Ù‡ Ø§Ø·Ø±Ø§Ù Ú©Ø§Ø±Ø§Ú©ØªØ±\n",
    "    x, y, w, h = cv2.boundingRect(main_contour)\n",
    "    char_img = isolated[y:y+h, x:x+w]\n",
    "\n",
    "    # Ø±ÛŒØ³Ø§ÛŒØ² Ø¨Ø§ Ø­ÙØ¸ Ù†Ø³Ø¨Øª\n",
    "    h_new, w_new = char_img.shape\n",
    "    scale = min((size[0] - 4) / h_new, (size[1] - 4) / w_new)\n",
    "    char_resized = cv2.resize(char_img, (int(w_new * scale), int(h_new * scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† ÙˆØ³Ø· ØªØµÙˆÛŒØ± Ø³ÙÛŒØ¯\n",
    "    final_img = np.ones(size, dtype=np.uint8) * 255\n",
    "    h_final, w_final = char_resized.shape\n",
    "    y_offset = (size[0] - h_final) // 2\n",
    "    x_offset = (size[1] - w_final) // 2\n",
    "    final_img[y_offset:y_offset+h_final, x_offset:x_offset+w_final] = 255 - char_resized  # Ø¨Ø±Ø¹Ú©Ø³Ø´ Ú©Ù†ÛŒÙ… Ú†ÙˆÙ† Ø§ÛŒÙ†ÙˆØ±Øª Ø´Ø¯Ù‡ Ø¨ÙˆØ¯\n",
    "\n",
    "    return final_img\n",
    "\n",
    "# Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±\n",
    "for filename in tqdm(os.listdir(input_dir)):\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    img = cv2.imread(input_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    cleaned_img = clean_and_center_image(img)\n",
    "    cv2.imwrite(output_path, cleaned_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3321b95",
   "metadata": {},
   "source": [
    "# ÙØ§Ø² 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ac998",
   "metadata": {},
   "source": [
    "### Ø¢Ù…Ø§Ø¯Ù‡ Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0435894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adbf1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_dir = 'alpha'\n",
    "output_dir = 'output_phase3'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for folder_name in os.listdir(input_dir):\n",
    "    input_folder_path = os.path.join(input_dir, folder_name)\n",
    "    \n",
    "    if os.path.isdir(input_folder_path):\n",
    "        output_folder_path = os.path.join(output_dir, folder_name)\n",
    "        os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "        for img_name in os.listdir(input_folder_path):\n",
    "            input_img_path = os.path.join(input_folder_path, img_name)\n",
    "            output_img_path = os.path.join(output_folder_path, img_name)\n",
    "\n",
    "            try:\n",
    "                with Image.open(input_img_path) as img:\n",
    "                    resized_img = img.resize((28, 28), Image.LANCZOS)  # â† Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø¨Ù‡ØªØ±\n",
    "                    resized_img.save(output_img_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¹Ú©Ø³ {input_img_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c4f97",
   "metadata": {},
   "source": [
    "### Ø§Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb049cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage.feature import hog\n",
    "import joblib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c2ca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:01<00:00, 26.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Ù…Ø¬Ù…ÙˆØ¹ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ (Ø´Ø§Ù…Ù„ Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ú†Ø±Ø®Ø´â€ŒØ¯Ø§Ø±): 8598\n",
      "âš™ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¹Ù…Ø§Ù„ PCA Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø¨Ø¹Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§...\n",
      "\n",
      "ğŸ“ Ø¢Ù…ÙˆØ²Ø´ SVM...\n",
      "ğŸ¯ Ø¯Ù‚Øª SVM: 0.87\n",
      "\n",
      "ğŸ“ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ…...\n",
      "ğŸŒ³ Ø¯Ù‚Øª Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ…: 0.64\n",
      "\n",
      "âœ… Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ PCA Ø¯Ø± Ù¾ÙˆØ´Ù‡ output_phase3.1 Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_dir = 'output_phase3'\n",
    "output_dir = 'output_phase3.1'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "image_size = (28, 28)\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "label_names = sorted(os.listdir(input_dir))\n",
    "label_map = {name: idx for idx, name in enumerate(label_names)}\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø³ÛŒØ§Ù‡ Ùˆ Ø³ÙÛŒØ¯\n",
    "    _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Ø­Ø°Ù ÙØ¶Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ\n",
    "    x, y_, w, h = cv2.boundingRect(binary)\n",
    "    cropped = binary[y_:y_+h, x:x+w]\n",
    "\n",
    "    # ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡\n",
    "    resized = cv2.resize(cropped, image_size)\n",
    "    return resized\n",
    "\n",
    "def augment_image(img):\n",
    "    rows, cols = img.shape\n",
    "    angle = np.random.uniform(-10, 10)\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1.0)\n",
    "    return cv2.warpAffine(img, M, (cols, rows), borderValue=255)\n",
    "\n",
    "print(\"Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±...\")\n",
    "\n",
    "for label_name in tqdm(label_names):\n",
    "    folder_path = os.path.join(input_dir, label_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§ØµÙ„ÛŒ\n",
    "            pre_img = preprocess_image(img)\n",
    "\n",
    "            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ Ø§ØµÙ„ÛŒ\n",
    "            features = hog(pre_img,\n",
    "                           orientations=orientations,\n",
    "                           pixels_per_cell=pixels_per_cell,\n",
    "                           cells_per_block=cells_per_block,\n",
    "                           block_norm='L2-Hys',\n",
    "                           visualize=False)\n",
    "            X.append(features)\n",
    "            y.append(label_map[label_name])\n",
    "\n",
    "            # Augmented Ù†Ø³Ø®Ù‡ Ú†Ø±Ø®Ø´â€ŒØ¯Ø§Ø±\n",
    "            aug_img = augment_image(pre_img)\n",
    "            features_aug = hog(aug_img,\n",
    "                               orientations=orientations,\n",
    "                               pixels_per_cell=pixels_per_cell,\n",
    "                               cells_per_block=cells_per_block,\n",
    "                               block_norm='L2-Hys',\n",
    "                               visualize=False)\n",
    "            X.append(features_aug)\n",
    "            y.append(label_map[label_name])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ {img_path}: {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"\\nğŸ“Š Ù…Ø¬Ù…ÙˆØ¹ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ (Ø´Ø§Ù…Ù„ Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ú†Ø±Ø®Ø´â€ŒØ¯Ø§Ø±): {X.shape[0]}\")\n",
    "\n",
    "# Ú©Ø§Ù‡Ø´ Ø§Ø¨Ø¹Ø§Ø¯ Ø¨Ø§ PCA\n",
    "print(\"âš™ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¹Ù…Ø§Ù„ PCA Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø¨Ø¹Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§...\")\n",
    "pca = PCA(n_components=50)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# ØªÙ‚Ø³ÛŒÙ… Ø¢Ù…ÙˆØ²Ø´/ØªØ³Øª\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ø¢Ù…ÙˆØ²Ø´ SVM\n",
    "print(\"\\nğŸ“ Ø¢Ù…ÙˆØ²Ø´ SVM...\")\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_acc = accuracy_score(y_test, svm_model.predict(X_test))\n",
    "print(f\"ğŸ¯ Ø¯Ù‚Øª SVM: {svm_acc:.2f}\")\n",
    "\n",
    "# Ø¢Ù…ÙˆØ²Ø´ Decision Tree\n",
    "print(\"\\nğŸ“ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ…...\")\n",
    "dt_model = DecisionTreeClassifier(max_depth=15)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_acc = accuracy_score(y_test, dt_model.predict(X_test))\n",
    "print(f\"ğŸŒ³ Ø¯Ù‚Øª Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ…: {dt_acc:.2f}\")\n",
    "\n",
    "# Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ PCA\n",
    "joblib.dump(svm_model, os.path.join(output_dir, 'svm_model.joblib'))\n",
    "joblib.dump(dt_model, os.path.join(output_dir, 'decision_tree_model.joblib'))\n",
    "joblib.dump(pca, os.path.join(output_dir, 'pca_transform.joblib'))\n",
    "\n",
    "print(f\"\\nâœ… Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ PCA Ø¯Ø± Ù¾ÙˆØ´Ù‡ {output_dir} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f054a3",
   "metadata": {},
   "source": [
    "# ÙØ§Ø² 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0f71f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ù†ØªØ§ÛŒØ¬ Ø¯Ø± output_phase4\\results.txt Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "\n",
    "# Ù…Ø³ÛŒØ±Ù‡Ø§\n",
    "input_folder = 'output_phase2.4'\n",
    "model_folder = 'output_phase3.2'\n",
    "output_folder = 'output_phase4'\n",
    "\n",
    "# Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§\n",
    "svm_model = load(os.path.join(model_folder, 'svm_model.joblib'))\n",
    "tree_model = load(os.path.join(model_folder, 'tree_model.joblib'))\n",
    "\n",
    "# Ù…Ø´Ø®Øµ Ú©Ø±Ø¯Ù† Ø§Ø¨Ø¹Ø§Ø¯ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± Ù…Ø¯Ù„\n",
    "expected_features = svm_model.n_features_in_\n",
    "img_width = 42\n",
    "img_height = expected_features // img_width  # Ù…Ø«Ù„Ø§Ù‹ 2352 // 42 = 56\n",
    "\n",
    "# Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ\n",
    "results = []\n",
    "\n",
    "for filename in sorted(os.listdir(input_folder)):\n",
    "    if not filename.lower().endswith('.png'):\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(input_folder, filename)\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† ØªØµÙˆÛŒØ± Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†Ù…: {filepath}\")\n",
    "        continue\n",
    "\n",
    "    # ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± Ù…Ø¯Ù„\n",
    "    resized = cv2.resize(img, (img_width, img_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø± ÙˆÛŒÚ˜Ú¯ÛŒ\n",
    "    features = resized.flatten().reshape(1, -1)\n",
    "\n",
    "    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§ Ø¯Ùˆ Ù…Ø¯Ù„\n",
    "    svm_pred = svm_model.predict(features)[0]\n",
    "    tree_pred = tree_model.predict(features)[0]\n",
    "\n",
    "    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡\n",
    "    results.append((filename, svm_pred, tree_pred))\n",
    "\n",
    "# Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„\n",
    "output_file = os.path.join(output_folder, 'results.txt')\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write('filename\\tSVM_prediction\\tDecisionTree_prediction\\n')\n",
    "    for filename, svm_pred, tree_pred in results:\n",
    "        f.write(f\"{filename}\\t{svm_pred}\\t{tree_pred}\\n\")\n",
    "\n",
    "print(f\"âœ… Ù†ØªØ§ÛŒØ¬ Ø¯Ø± {output_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be37007",
   "metadata": {},
   "source": [
    "# ÙØ§Ø² 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44c3e869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯.\n",
      "SVM Accuracy: 0.0000\n",
      "Decision Tree Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ ÙØ§Ø² Û´\n",
    "input_txt_path = \"output_phase4/results.txt\"\n",
    "\n",
    "# Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„\n",
    "if not os.path.exists(input_txt_path):\n",
    "    raise FileNotFoundError(f\"ÙØ§ÛŒÙ„ {input_txt_path} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.\")\n",
    "\n",
    "# Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ù…ØªÙ†ÛŒ Ùˆ Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…\n",
    "with open(input_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "data = []\n",
    "for line in lines[1:]:  # Ø±Ø¯ Ú©Ø±Ø¯Ù† Ù‡Ø¯Ø±\n",
    "    parts = line.strip().split(\"\\t\")\n",
    "    if len(parts) == 3:\n",
    "        data.append(parts)\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"name\", \"SVM_prediction\", \"DecisionTree_prediction\"])\n",
    "\n",
    "# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø±Ú†Ø³Ø¨ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² Ù†Ø§Ù… ÙØ§ÛŒÙ„ (Ù…Ø«Ù„Ø§Ù‹ 104_char2.png â†’ 104)\n",
    "df[\"true_label\"] = df[\"name\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "# Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ\n",
    "y_true = df[\"true_label\"]\n",
    "svm_pred = df[\"SVM_prediction\"]\n",
    "tree_pred = df[\"DecisionTree_prediction\"]\n",
    "\n",
    "# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§\n",
    "svm_acc = accuracy_score(y_true, svm_pred)\n",
    "tree_acc = accuracy_score(y_true, tree_pred)\n",
    "svm_report = classification_report(y_true, svm_pred, zero_division=0)\n",
    "tree_report = classification_report(y_true, tree_pred, zero_division=0)\n",
    "svm_cm = confusion_matrix(y_true, svm_pred)\n",
    "tree_cm = confusion_matrix(y_true, tree_pred)\n",
    "\n",
    "# Ø³Ø§Ø®Øª Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "output_dir = \"output_phase5\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ Ù…ØªÙ†ÛŒ\n",
    "with open(os.path.join(output_dir, \"evaluation.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"SVM Accuracy: {svm_acc:.4f}\\n\")\n",
    "    f.write(f\"Decision Tree Accuracy: {tree_acc:.4f}\\n\\n\")\n",
    "\n",
    "    f.write(\"=== SVM Classification Report ===\\n\")\n",
    "    f.write(svm_report + \"\\n\")\n",
    "    f.write(\"=== SVM Confusion Matrix ===\\n\")\n",
    "    f.write(str(svm_cm) + \"\\n\\n\")\n",
    "\n",
    "    f.write(\"=== Decision Tree Classification Report ===\\n\")\n",
    "    f.write(tree_report + \"\\n\")\n",
    "    f.write(\"=== Decision Tree Confusion Matrix ===\\n\")\n",
    "    f.write(str(tree_cm) + \"\\n\")\n",
    "\n",
    "# --- Ú†Ø§Ù¾ Ø¯Ø± ØªØ±Ù…ÛŒÙ†Ø§Ù„ ---\n",
    "print(\"âœ… Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯.\")\n",
    "print(f\"SVM Accuracy: {svm_acc:.4f}\")\n",
    "print(f\"Decision Tree Accuracy: {tree_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
