{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8397fdda",
   "metadata": {},
   "source": [
    "# Ø¨Ù‡ Ù†Ø§Ù… Ø®Ø¯Ø§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81215f",
   "metadata": {},
   "source": [
    "# ÙØ§Ø² 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "259fd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49cd300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±:   0%|          | 0/217 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 217/217 [00:05<00:00, 36.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§Ø² Ø§ÙˆÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ù¾Ù„Ø§Ú©â€ŒÙ‡Ø§ Ø¯Ø± Ù¾ÙˆØ´Ù‡ 'output_phase1' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Ù†Ø³Ø¨Øª Ø¨Ø²Ø±Ú¯Ù†Ù…Ø§ÛŒÛŒ\n",
    "SCALE_X = 1280 / 224\n",
    "SCALE_Y = 1280 / 224\n",
    "\n",
    "def parse_annotation(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    plates = []\n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text\n",
    "        if name.lower() == 'vehicle plate':\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = int(int(bndbox.find('xmin').text) * SCALE_X)\n",
    "            ymin = int(int(bndbox.find('ymin').text) * SCALE_Y)\n",
    "            xmax = int(int(bndbox.find('xmax').text) * SCALE_X)\n",
    "            ymax = int(int(bndbox.find('ymax').text) * SCALE_Y)\n",
    "            plates.append((xmin, ymin, xmax, ymax))\n",
    "    \n",
    "    return plates\n",
    "\n",
    "def extract_plates(image_path, annotation_path, output_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ØªØµÙˆÛŒØ±: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    plates = parse_annotation(annotation_path)\n",
    "    if not plates:\n",
    "        print(f\"Ù‡ÛŒÚ† Ù¾Ù„Ø§Ú©ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ Ø¢Ù†ÙˆØªÛŒØ´Ù† ÛŒØ§ÙØª Ù†Ø´Ø¯: {annotation_path}\")\n",
    "        return\n",
    "    \n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    for i, (xmin, ymin, xmax, ymax) in enumerate(plates):\n",
    "        plate_img = image[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        output_file = os.path.join(output_path, f\"{base_name}.png\")\n",
    "        cv2.imwrite(output_file, plate_img)\n",
    "\n",
    "def process_dataset(base_dir, output_dir):\n",
    "    images_dir = os.path.join(base_dir, \"Vehicle Plates 1280x1280\", \"Vehicle Plates 1280x1280\")\n",
    "    annotations_dir = os.path.join(base_dir, \"Vehicle Plates annotations\", \"Vehicle Plates annotations\")\n",
    "    \n",
    "    if not os.path.exists(images_dir):\n",
    "        print(f\"Ù¾ÙˆØ´Ù‡ ØªØµØ§ÙˆÛŒØ± ÛŒØ§ÙØª Ù†Ø´Ø¯: {images_dir}\")\n",
    "        return\n",
    "    if not os.path.exists(annotations_dir):\n",
    "        print(f\"Ù¾ÙˆØ´Ù‡ Ø¢Ù†ÙˆØªÛŒØ´Ù†â€ŒÙ‡Ø§ ÛŒØ§ÙØª Ù†Ø´Ø¯: {annotations_dir}\")\n",
    "        return\n",
    "    \n",
    "    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for img_file in tqdm(image_files, desc=\"Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±\"):\n",
    "        base_name = os.path.splitext(img_file)[0]\n",
    "        image_path = os.path.join(images_dir, img_file)\n",
    "        annotation_path = os.path.join(annotations_dir, f\"{base_name}.xml\")\n",
    "        \n",
    "        if os.path.exists(annotation_path):\n",
    "            extract_plates(image_path, annotation_path, output_dir)\n",
    "        else:\n",
    "            print(f\"ÙØ§ÛŒÙ„ Ø¢Ù†ÙˆØªÛŒØ´Ù† ÛŒØ§ÙØª Ù†Ø´Ø¯: {annotation_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"Plates2\"\n",
    "    output_dir = \"output_phase1\"\n",
    "    \n",
    "    process_dataset(base_dir, output_dir)\n",
    "    \n",
    "    print(f\"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§Ø² Ø§ÙˆÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ù¾Ù„Ø§Ú©â€ŒÙ‡Ø§ Ø¯Ø± Ù¾ÙˆØ´Ù‡ '{output_dir}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c34b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "029a3767",
   "metadata": {},
   "source": [
    "# ÙØ§Ø² 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f5693a",
   "metadata": {},
   "source": [
    "### Ø¯Ø±Ø³Øª Ú©Ø±Ø¯Ù† Ú©Ø¬ÛŒ Ùˆ Ø³ÛŒØ§Ù‡ Ø³ÙÛŒØ¯ Ú©Ø±Ø¯Ù†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc24193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f24242e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ø§ØµÙ„Ø§Ø­ Ø²Ø§ÙˆÛŒÙ‡ Ø¨Ø§ ØªØ±Ú©ÛŒØ¨ minAreaRect + Hough Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_folder = 'output_phase1'\n",
    "output_folder = 'output_phase2'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "def angle_from_min_area_rect(thresh):\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    largest = max(contours, key=cv2.contourArea)\n",
    "    rect = cv2.minAreaRect(largest)\n",
    "    angle = rect[-1]\n",
    "    if angle < -45:\n",
    "        angle += 90\n",
    "    elif angle > 45:\n",
    "        angle -= 90\n",
    "    return angle\n",
    "\n",
    "def angle_from_hough(gray):\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, minLineLength=30, maxLineGap=10)\n",
    "    if lines is None:\n",
    "        return None\n",
    "    angles = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "        if -45 < angle < 45:\n",
    "            angles.append(angle)\n",
    "    if not angles:\n",
    "        return None\n",
    "    return np.median(angles)\n",
    "\n",
    "def correct_skew_combined(gray_image, angle_threshold=3):\n",
    "    # Preprocess\n",
    "    _, thresh = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    thresh = 255 - thresh\n",
    "\n",
    "    # Step 1: try minAreaRect\n",
    "    angle = angle_from_min_area_rect(thresh)\n",
    "\n",
    "    # Step 2: fallback to HoughLines if angle too small or None\n",
    "    if angle is None or abs(angle) < angle_threshold:\n",
    "        angle = angle_from_hough(gray_image)\n",
    "\n",
    "    # Ø§Ú¯Ø± Ù‡Ù…Ú†Ù†Ø§Ù† Ø²Ø§ÙˆÛŒÙ‡ Ù…Ø¹Ù†Ø§Ø¯Ø§Ø± Ù†Ø¨ÙˆØ¯ØŒ ØªØµÙˆÛŒØ± Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†\n",
    "    if angle is None or abs(angle) < angle_threshold:\n",
    "        return gray_image\n",
    "\n",
    "    # Rotate\n",
    "    (h, w) = gray_image.shape\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(gray_image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "# Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ù‡ ØªØµØ§ÙˆÛŒØ±\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "        path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        corrected = correct_skew_combined(gray)\n",
    "\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, corrected)\n",
    "\n",
    "print(\"âœ… Ø§ØµÙ„Ø§Ø­ Ø²Ø§ÙˆÛŒÙ‡ Ø¨Ø§ ØªØ±Ú©ÛŒØ¨ minAreaRect + Hough Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be0ea65",
   "metadata": {},
   "source": [
    "### Ú©Ø§Øª Ø¯Ø§Ø¯Ù† ÛŒÚ© Ù‡Ø´ØªÙ… Ø§ÙˆÙ„ Ù¾Ù„Ø§Ú©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10779d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95457256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙ…Ø§Ù… Ø´Ø¯.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "input_dir = 'output_phase2'\n",
    "output_dir = 'output_phase2.1'\n",
    "\n",
    "# Ø³Ø§Ø®Øª Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´Øª\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø± ØªØµÙˆÛŒØ± Ø¯Ø± Ù¾ÙˆØ´Ù‡ ÙˆØ±ÙˆØ¯ÛŒ\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tif')):\n",
    "        img_path = os.path.join(input_dir, filename)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Ø§Ø¨Ø¹Ø§Ø¯ ØªØµÙˆÛŒØ±\n",
    "        width, height = img.size\n",
    "\n",
    "        # Ø¹Ø±Ø¶ Ù‡Ø± ØªÚ©Ù‡\n",
    "        slice_width = width // 8\n",
    "\n",
    "        # Ø¨Ø±Ø´ ØªØµÙˆÛŒØ±: Ø­Ø°Ù ØªÛŒÚ©Ù‡ Ø§ÙˆÙ„ (Ø§Ø² x=0 ØªØ§ x=slice_width)\n",
    "        # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† Ø¨Ø®Ø´ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ (Ø§Ø² x=slice_width ØªØ§ x=width)\n",
    "        cropped_img = img.crop((slice_width, 0, width, height))\n",
    "\n",
    "        # Ø°Ø®ÛŒØ±Ù‡ ØªØµÙˆÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cropped_img.save(output_path)\n",
    "\n",
    "print(\"Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙ…Ø§Ù… Ø´Ø¯.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea3df5",
   "metadata": {},
   "source": [
    "### Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ú©Ø±Ø¯Ù† Ø¹Ú©Ø³ Ù‡Ø§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa039ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd13ae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ø¨Ø§ Ø­ÙØ¸ Ø¬Ø²Ø¦ÛŒØ§Øª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_folder = 'output_phase2.1'\n",
    "output_folder = 'output_phase2.2'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # 1. Ù†ÙˆÛŒØ²Ø²Ø¯Ø§ÛŒÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ± ØºÛŒØ±Ù…Ø­Ù„ÛŒ (Non-local Means)\n",
    "        denoised = cv2.fastNlMeansDenoising(img, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "\n",
    "        # 2. Ø§ÙØ²Ø§ÛŒØ´ Ú©Ù†ØªØ±Ø§Ø³Øª Ø¨Ø§ CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        contrast_enhanced = clahe.apply(denoised)\n",
    "\n",
    "        # 3. Ù†Ø±Ù… Ú©Ø±Ø¯Ù† Ø¨Ø§ ÙÛŒÙ„ØªØ± Ú¯ÙˆØ³ÛŒ\n",
    "        blurred = cv2.GaussianBlur(contrast_enhanced, (3, 3), 0)\n",
    "\n",
    "        # 4. Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ ØªØ·Ø¨ÛŒÙ‚ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø§ÛŒÙ†Ø±ÛŒâ€ŒØ³Ø§Ø²ÛŒ\n",
    "        binary_img = cv2.adaptiveThreshold(\n",
    "            blurred,\n",
    "            255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY_INV,\n",
    "            11,  # Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ù„ÙˆÚ©\n",
    "            2    # Ù…Ù‚Ø¯Ø§Ø± Ø«Ø§Ø¨Øª\n",
    "        )\n",
    "\n",
    "        # 5. Ø­Ø°Ù Ù†ÙˆÛŒØ²Ù‡Ø§ÛŒ Ú©ÙˆÚ†Ú© Ø¨Ø§ Ù…ÙˆØ±ÙÙˆÙ„ÙˆÚ˜ÛŒ\n",
    "        kernel = np.ones((2, 2), np.uint8)\n",
    "        processed = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # 6. Ù¾Ø± Ú©Ø±Ø¯Ù† Ø­ÙØ±Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§\n",
    "        h, w = processed.shape\n",
    "        flood_fill_mask = np.zeros((h + 2, w + 2), np.uint8)\n",
    "        im_floodfill = processed.copy()\n",
    "\n",
    "        # ÙÛŒÙ„ Ú©Ø±Ø¯Ù† Ø§Ø² ÛŒÚ© Ù†Ù‚Ø·Ù‡â€ŒÛŒ Ù…Ø·Ù…Ø¦Ù† (Ú¯ÙˆØ´Ù‡â€ŒÛŒ ØªØµÙˆÛŒØ±)\n",
    "        cv2.floodFill(im_floodfill, flood_fill_mask, (0, 0), 255)\n",
    "\n",
    "        # ÛŒØ§ÙØªÙ† Ø­ÙØ±Ù‡â€ŒÙ‡Ø§ Ùˆ Ù¾Ø± Ú©Ø±Ø¯Ù† Ø¢Ù†â€ŒÙ‡Ø§\n",
    "        holes = cv2.bitwise_not(im_floodfill) & processed\n",
    "        filled = processed | holes\n",
    "\n",
    "        # 7. Ù…Ø¹Ú©ÙˆØ³ Ú©Ø±Ø¯Ù†: Ù…ØªÙ† Ø³ÙÛŒØ¯ØŒ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø³ÛŒØ§Ù‡\n",
    "        final_img = cv2.bitwise_not(filled)\n",
    "\n",
    "        # 8. Ø°Ø®ÛŒØ±Ù‡ ØªØµÙˆÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, final_img)\n",
    "\n",
    "print(\"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ø¨Ø§ Ø­ÙØ¸ Ø¬Ø²Ø¦ÛŒØ§Øª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18e54b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§ Ø­ÙØ¸ Ø­Ø¯Ø§Ú©Ø«Ø± Ú©ÛŒÙÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_folder = 'output_phase2.1'\n",
    "output_folder = 'output_phase2.2'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # 1. Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø§ Ø­ÙØ¸ Ø¬Ø²Ø¦ÛŒØ§Øª\n",
    "        denoised = cv2.fastNlMeansDenoising(img, h=5, templateWindowSize=7, searchWindowSize=21)\n",
    "        \n",
    "        # 2. Ø§ÙØ²Ø§ÛŒØ´ Ú©Ù†ØªØ±Ø§Ø³Øª Ù‡ÙˆØ´Ù…Ù†Ø¯\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(12,12))\n",
    "        contrast_enhanced = clahe.apply(denoised)\n",
    "        \n",
    "        # 3. Ø¨Ù‡Ø¨ÙˆØ¯ Ù„Ø¨Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ ÙÛŒÙ„ØªØ± ÙˆÛŒÚ˜Ù‡\n",
    "        blurred = cv2.bilateralFilter(contrast_enhanced, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "        \n",
    "        # 4. Ø±ÙˆØ´ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ\n",
    "        # Ù…Ø±Ø­Ù„Ù‡ Ø§ÙˆÙ„: Adaptive Threshold\n",
    "        binary_adaptive = cv2.adaptiveThreshold(\n",
    "            blurred,\n",
    "            255,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY_INV,\n",
    "            blockSize=9,\n",
    "            C=2\n",
    "        )\n",
    "        \n",
    "        # Ù…Ø±Ø­Ù„Ù‡ Ø¯ÙˆÙ…: Otsu Threshold\n",
    "        _, binary_otsu = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Ù…Ø±Ø­Ù„Ù‡ Ø³ÙˆÙ…: ØªØ±Ú©ÛŒØ¨ Ø¨Ø§ ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ\n",
    "        combined = cv2.addWeighted(binary_adaptive, 0.7, binary_otsu, 0.3, 0)\n",
    "        \n",
    "        # 5. Ø¨Ù‡Ø¨ÙˆØ¯ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ ØªÚ©Ù†ÛŒÚ© Super-Resolution (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\n",
    "        # Ø§Ú¯Ø± opencv Ø¨Ø§ contrib Ù†ØµØ¨ Ø¨Ø§Ø´Ø¯:\n",
    "        # super_res = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "        # super_res.readModel('EDSR_x4.pb')\n",
    "        # super_res.setModel('edsr', 4)\n",
    "        # final_img = super_res.upsample(combined)\n",
    "        \n",
    "        # 6. Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, cv2.bitwise_not(combined))\n",
    "\n",
    "print(\"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§ Ø­ÙØ¸ Ø­Ø¯Ø§Ú©Ø«Ø± Ú©ÛŒÙÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ef098",
   "metadata": {},
   "source": [
    "### Ø¯Ø± Ø§ÙˆØ±Ø¯Ù† Ú©Ø§Ø±Ø§Ú©ØªØ± Ù‡Ø§ÛŒ Ù‡Ø± Ø¹Ú©Ø³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1aec5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e64f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 1.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 10.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 100.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 101.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 102.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 103.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 104.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 105.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 106.png: 2 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 107.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 108.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 109.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 11.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 110.png: 5 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 111.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 112.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 113.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 114.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 115.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 116.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 117.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 118.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 119.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 12.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 120.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 121.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 122.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 123.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 124.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 125.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 126.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 127.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 128.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 129.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 13.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 130.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 131.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 132.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 133.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 134.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 135.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 136.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 137.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 138.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 139.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 14.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 140.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 141.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 142.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 143.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 144.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 145.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 146.png: 0 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 147.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 148.png: 0 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 149.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 15.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 150.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 151.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 152.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 153.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 154.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 155.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 156.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 157.png: 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 158.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 159.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 16.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 160.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 161.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 162.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 163.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 164.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 165.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 166.png: 1 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 167.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 168.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 169.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 17.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 170.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 171.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 172.png: 2 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 173.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 174.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 175.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 176.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 177.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 178.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 179.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 18.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 180.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 181.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 182.png: 1 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 183.png: 0 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 184.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 185.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 186.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 187.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 188.png: 1 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 189.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 19.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 190.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 191.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 192.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 193.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 194.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 195.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 196.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 197.png: 0 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 198.png: 0 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 199.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 2.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 20.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 200.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 201.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 202.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 203.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 204.png: 1 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 205.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 206.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 207.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 208.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 209.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 21.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 210.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 211.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 212.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 213.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 214.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 215.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 216.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 217.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 22.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 23.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 24.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 25.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 26.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 27.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 28.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 29.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 3.png: 0 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 30.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 31.png: 6 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 32.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 33.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 34.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 35.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 36.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 37.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 38.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 39.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 4.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 40.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 41.png: 0 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 42.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 43.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 44.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 45.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 46.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 47.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 48.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 49.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 5.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 50.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 51.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 52.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 53.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 54.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 55.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 56.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 57.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 58.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 59.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 6.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 60.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 61.png: 0 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 62.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 63.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 64.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 65.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 66.png: 7 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 67.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 68.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 69.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 7.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 70.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 71.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 72.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 73.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 74.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 75.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 76.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 77.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 78.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 79.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 8.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 80.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 81.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 82.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 83.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 84.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 85.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 86.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 87.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 88.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 89.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 9.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 90.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 91.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 92.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 93.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 94.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 95.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 96.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 97.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 98.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… 99.png: 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "ğŸ¯ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯ - Ø¯Ù‚ÛŒÙ‚ Ùˆ Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ 8 Ú©Ø§Ø±Ø§Ú©ØªØ±.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_folder = \"output_phase2.2\"\n",
    "output_folder = \"output_phase2.3\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(input_folder, filename)\n",
    "    img_original = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img_original is None:\n",
    "        print(f\"â›” Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† ØªØµÙˆÛŒØ± {filename} Ø±Ø§ Ø®ÙˆØ§Ù†Ø¯.\")\n",
    "        continue\n",
    "\n",
    "    # Ø¨Ø²Ø±Ú¯Ù†Ù…Ø§ÛŒÛŒ Ã—3\n",
    "    scale = 3\n",
    "    img_highres = cv2.resize(img_original, (img_original.shape[1]*scale, img_original.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # ØµØ§Ùâ€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ú©Ø±Ø¯Ù†\n",
    "    img_blur = cv2.GaussianBlur(img_highres, (3, 3), 0)\n",
    "    img_bin = cv2.adaptiveThreshold(\n",
    "        img_blur, 255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        15, 8\n",
    "    )\n",
    "\n",
    "    # Ø­Ø°Ù Ù†ÙˆÛŒØ²Ù‡Ø§ÛŒ Ú©ÙˆÚ†Ú©\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    img_bin = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ø§Ù†ØªÙˆØ±\n",
    "    contours, _ = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # ÙÙ‚Ø· Ø®Ø§Ø±Ø¬ÛŒ\n",
    "\n",
    "    # ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø¨Ø¹Ø§Ø¯ Ù†Ø³Ø¨ÛŒ (Ù‡ÙˆØ´Ù…Ù†Ø¯Ø§Ù†Ù‡â€ŒØªØ±)\n",
    "    boxes = []\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        area = cv2.contourArea(c)\n",
    "        if w < 10 or h < 20:\n",
    "            continue\n",
    "        if w > img_highres.shape[1] * 0.5 or h > img_highres.shape[0] * 0.9:\n",
    "            continue\n",
    "        if area < 100:\n",
    "            continue\n",
    "        boxes.append((x, y, w, h))\n",
    "\n",
    "    # ğŸ”§ Ø§Ú¯Ø± Ø®ÛŒÙ„ÛŒ Ú©Ø§Ù†ØªÙˆØ± Ø¯Ø§Ø±ÛŒÙ…ØŒ ÙÙ‚Ø· 8 ØªØ§ Ø§Ø² Ù…Ù†Ø§Ø³Ø¨â€ŒØªØ±ÛŒÙ†â€ŒÙ‡Ø§ Ø±Ùˆ Ø¨Ú¯ÛŒØ±ÛŒÙ…\n",
    "    if len(boxes) > 8:\n",
    "        boxes = sorted(boxes, key=lambda b: b[2]*b[3], reverse=True)  # Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø³Ø§Ø­Øª\n",
    "        boxes = boxes[:8]\n",
    "\n",
    "    # ğŸ”§ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø§Ø² Ú†Ù¾ Ø¨Ù‡ Ø±Ø§Ø³Øª\n",
    "    boxes = sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "    count = 0\n",
    "    pad = 6\n",
    "    for i, (x, y, w, h) in enumerate(boxes):\n",
    "        x_new = max(x - pad, 0)\n",
    "        y_new = max(y - pad, 0)\n",
    "        w_new = min(w + 2 * pad, img_highres.shape[1] - x_new)\n",
    "        h_new = min(h + 2 * pad, img_highres.shape[0] - y_new)\n",
    "\n",
    "        char_img = img_highres[y_new:y_new + h_new, x_new:x_new + w_new]\n",
    "\n",
    "        # ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡ Ùˆ Ø´Ø§Ø±Ù¾ Ú©Ø±Ø¯Ù†\n",
    "        char_img_resized = cv2.resize(char_img, (64, 128), interpolation=cv2.INTER_CUBIC)\n",
    "        kernel_sharp = np.array([[0, -1, 0],\n",
    "                                 [-1, 5, -1],\n",
    "                                 [0, -1, 0]])\n",
    "        char_img_resized = cv2.filter2D(char_img_resized, -1, kernel_sharp)\n",
    "\n",
    "        out_name = f\"{os.path.splitext(filename)[0]}_char{count + 1}.png\"\n",
    "        cv2.imwrite(os.path.join(output_folder, out_name), char_img_resized)\n",
    "        count += 1\n",
    "\n",
    "    print(f\"âœ… {filename}: {count} Ú©Ø§Ø±Ø§Ú©ØªØ± Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n",
    "\n",
    "print(\"ğŸ¯ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯ - Ø¯Ù‚ÛŒÙ‚ Ùˆ Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ 8 Ú©Ø§Ø±Ø§Ú©ØªØ±.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f62bb93",
   "metadata": {},
   "source": [
    "### ØªÙ†Ø¸ÛŒÙ… Ø³Ø§ÛŒØ² ØªØµØ§ÙˆÛŒØ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "477626e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0d300c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1612/1612 [00:01<00:00, 1402.84it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ù…Ø³ÛŒØ±Ù‡Ø§\n",
    "input_dir = 'output_phase2.3'\n",
    "output_dir = 'output_phase2.4'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def clean_and_center_image(img, size=(28, 28)):\n",
    "    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø®Ø§Ú©Ø³ØªØ±ÛŒ Ø§Ú¯Ø± Ø±Ù†Ú¯ÛŒ Ø¨ÙˆØ¯\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ú©Ø±Ø¯Ù† (Ù…ØªÙ† Ø³ÛŒØ§Ù‡ØŒ Ø²Ù…ÛŒÙ†Ù‡ Ø³ÙÛŒØ¯)\n",
    "    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Ø­Ø°Ù Ù†ÙˆÛŒØ² Ø¨Ø§ Morphology\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    clean = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¨Ø²Ø±Ú¯â€ŒØªØ±ÛŒÙ† Ú©Ø§Ù†ØªÙˆØ± (Ú©Ø§Ø±Ø§Ú©ØªØ± Ø§ØµÙ„ÛŒ)\n",
    "    contours, _ = cv2.findContours(clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return np.ones(size, dtype=np.uint8) * 255  # Ø¨Ø±Ú¯Ø±Ø¯ ØªØµÙˆÛŒØ± Ø³ÙÛŒØ¯ Ø®Ø§Ù„ÛŒ\n",
    "\n",
    "    # Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø²Ø±Ú¯â€ŒØªØ±ÛŒÙ† Ú©Ø§Ù†ØªÙˆØ±\n",
    "    main_contour = max(contours, key=cv2.contourArea)\n",
    "    mask = np.zeros_like(clean)\n",
    "    cv2.drawContours(mask, [main_contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    # ÙÙ‚Ø· Ú©Ø§Ø±Ø§Ú©ØªØ± Ø§ØµÙ„ÛŒ Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø´Ù‡\n",
    "    isolated = cv2.bitwise_and(clean, mask)\n",
    "\n",
    "    # Ú©Ø±Ø§Ù¾ Ø¨Ù‡ Ø§Ø·Ø±Ø§Ù Ú©Ø§Ø±Ø§Ú©ØªØ±\n",
    "    x, y, w, h = cv2.boundingRect(main_contour)\n",
    "    char_img = isolated[y:y+h, x:x+w]\n",
    "\n",
    "    # Ø±ÛŒØ³Ø§ÛŒØ² Ø¨Ø§ Ø­ÙØ¸ Ù†Ø³Ø¨Øª\n",
    "    h_new, w_new = char_img.shape\n",
    "    scale = min((size[0] - 4) / h_new, (size[1] - 4) / w_new)\n",
    "    char_resized = cv2.resize(char_img, (int(w_new * scale), int(h_new * scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† ÙˆØ³Ø· ØªØµÙˆÛŒØ± Ø³ÙÛŒØ¯\n",
    "    final_img = np.ones(size, dtype=np.uint8) * 255\n",
    "    h_final, w_final = char_resized.shape\n",
    "    y_offset = (size[0] - h_final) // 2\n",
    "    x_offset = (size[1] - w_final) // 2\n",
    "    final_img[y_offset:y_offset+h_final, x_offset:x_offset+w_final] = 255 - char_resized  # Ø¨Ø±Ø¹Ú©Ø³Ø´ Ú©Ù†ÛŒÙ… Ú†ÙˆÙ† Ø§ÛŒÙ†ÙˆØ±Øª Ø´Ø¯Ù‡ Ø¨ÙˆØ¯\n",
    "\n",
    "    return final_img\n",
    "\n",
    "# Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±\n",
    "for filename in tqdm(os.listdir(input_dir)):\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    img = cv2.imread(input_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    cleaned_img = clean_and_center_image(img)\n",
    "    cv2.imwrite(output_path, cleaned_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3321b95",
   "metadata": {},
   "source": [
    "# ÙØ§Ø² 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ac998",
   "metadata": {},
   "source": [
    "### Ø¢Ù…Ø§Ø¯Ù‡ Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0435894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "adbf1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "input_dir = 'alpha'\n",
    "output_dir = 'output_phase3'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def crop_white_borders(image):\n",
    "    \"\"\"Ø¨Ø±Ø´ Ø¯Ø§Ø¯Ù† Ù†ÙˆØ§Ø­ÛŒ Ø³ÙÛŒØ¯ Ø§Ø·Ø±Ø§Ù ØªØµÙˆÛŒØ±\"\"\"\n",
    "    bg = Image.new(image.mode, image.size, (255, 255, 255))  # Ø²Ù…ÛŒÙ†Ù‡ Ø³ÙÛŒØ¯\n",
    "    diff = ImageChops.difference(image, bg)\n",
    "    bbox = diff.getbbox()\n",
    "    return image.crop(bbox) if bbox else image\n",
    "\n",
    "def paste_on_white_canvas(image, size=(28, 28)):\n",
    "    \"\"\"Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† ØªØµÙˆÛŒØ± Ø¯Ø± Ø¨ÙˆÙ… Ø³ÙÛŒØ¯ Ùˆ ÙˆØ³Ø·â€ŒÚ†ÛŒÙ† Ú©Ø±Ø¯Ù† Ø¢Ù†\"\"\"\n",
    "    canvas = Image.new(\"RGB\", size, (255, 255, 255))  # â† Ø¨ÙˆÙ… Ø³ÙÛŒØ¯\n",
    "    img_w, img_h = image.size\n",
    "    scale = min(size[0] / img_w, size[1] / img_h)\n",
    "    new_size = (int(img_w * scale), int(img_h * scale))\n",
    "    image = image.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "    paste_x = (size[0] - new_size[0]) // 2\n",
    "    paste_y = (size[1] - new_size[1]) // 2\n",
    "    canvas.paste(image, (paste_x, paste_y))\n",
    "    return canvas\n",
    "\n",
    "for folder_name in os.listdir(input_dir):\n",
    "    input_folder_path = os.path.join(input_dir, folder_name)\n",
    "    \n",
    "    if os.path.isdir(input_folder_path):\n",
    "        output_folder_path = os.path.join(output_dir, folder_name)\n",
    "        os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "        for img_name in os.listdir(input_folder_path):\n",
    "            input_img_path = os.path.join(input_folder_path, img_name)\n",
    "            output_img_path = os.path.join(output_folder_path, img_name)\n",
    "\n",
    "            try:\n",
    "                with Image.open(input_img_path) as img:\n",
    "                    img = img.convert(\"RGB\")\n",
    "                    cropped_img = crop_white_borders(img)\n",
    "                    final_img = paste_on_white_canvas(cropped_img, size=(28, 28))\n",
    "                    final_img.save(output_img_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¹Ú©Ø³ {input_img_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c4f97",
   "metadata": {},
   "source": [
    "### Ø§Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8eb049cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d8eb6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:02<00:00, 17.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ (Ø¨Ø§ Augmentation): 7798\n",
      "âš™ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¹Ù…Ø§Ù„ PCA...\n",
      "\n",
      "ğŸ“ Ø¢Ù…ÙˆØ²Ø´ SVM...\n",
      "ğŸ¯ Ø¯Ù‚Øª SVM Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´: 0.98\n",
      "ğŸ¯ Ø¯Ù‚Øª SVM Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª: 0.96\n",
      "\n",
      "ğŸ“ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… (Ø¨Ø§ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Overfitting)...\n",
      "ğŸŒ³ Ø¯Ù‚Øª Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´: 0.84\n",
      "ğŸŒ³ Ø¯Ù‚Øª Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª: 0.76\n",
      "\n",
      "ğŸ” Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† ØªÙ†Ø¸ÛŒÙ…Ø§Øª Random Forest Ø¨Ø§ GridSearch...\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "ğŸŒ² Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Random Forest: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "ğŸŒ² Ø¯Ù‚Øª Random Forest Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´: 1.00\n",
      "ğŸŒ² Ø¯Ù‚Øª Random Forest Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª: 0.93\n",
      "\n",
      "âœ… Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ PCA Ø¯Ø± Ù…Ø³ÛŒØ± output_phase3.1 Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ù…Ø³ÛŒØ±Ù‡Ø§\n",
    "input_dir = 'output_phase3'                 # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ\n",
    "output_dir = 'output_phase3.1'              # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ HOG\n",
    "image_size = (28, 28)\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ø§Ø² Ù†Ø§Ù… Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§\n",
    "label_names = sorted(os.listdir(input_dir))\n",
    "label_map = {name: idx for idx, name in enumerate(label_names)}\n",
    "\n",
    "def preprocess_image(img):\n",
    "    _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    x, y_, w, h = cv2.boundingRect(binary)\n",
    "    cropped = binary[y_:y_+h, x:x+w]\n",
    "    resized = cv2.resize(cropped, image_size)\n",
    "    return resized\n",
    "\n",
    "def augment_image(img):\n",
    "    rows, cols = img.shape\n",
    "    angle = np.random.uniform(-10, 10)\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1.0)\n",
    "    return cv2.warpAffine(img, M, (cols, rows), borderValue=255)\n",
    "\n",
    "print(\"ğŸš€ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±...\")\n",
    "\n",
    "for label_name in tqdm(label_names):\n",
    "    folder_path = os.path.join(input_dir, label_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            pre_img = preprocess_image(img)\n",
    "\n",
    "            # ÙˆÛŒÚ˜Ú¯ÛŒ Ø§ØµÙ„ÛŒ\n",
    "            features = hog(pre_img,\n",
    "                           orientations=orientations,\n",
    "                           pixels_per_cell=pixels_per_cell,\n",
    "                           cells_per_block=cells_per_block,\n",
    "                           block_norm='L2-Hys',\n",
    "                           visualize=False)\n",
    "            X.append(features)\n",
    "            y.append(label_map[label_name])\n",
    "\n",
    "            # Ù†Ø³Ø®Ù‡ Ú†Ø±Ø®Ø´â€ŒØ¯Ø§Ø±\n",
    "            aug_img = augment_image(pre_img)\n",
    "            features_aug = hog(aug_img,\n",
    "                               orientations=orientations,\n",
    "                               pixels_per_cell=pixels_per_cell,\n",
    "                               cells_per_block=cells_per_block,\n",
    "                               block_norm='L2-Hys',\n",
    "                               visualize=False)\n",
    "            X.append(features_aug)\n",
    "            y.append(label_map[label_name])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ {img_path}: {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"\\nğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ (Ø¨Ø§ Augmentation): {X.shape[0]}\")\n",
    "\n",
    "# Ú©Ø§Ù‡Ø´ Ø¨Ø¹Ø¯ Ø¨Ø§ PCA\n",
    "print(\"âš™ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¹Ù…Ø§Ù„ PCA...\")\n",
    "pca = PCA(n_components=50)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# ØªÙ‚Ø³ÛŒÙ… Ø¢Ù…ÙˆØ²Ø´/ØªØ³Øª\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ø¢Ù…ÙˆØ²Ø´ SVM\n",
    "print(\"\\nğŸ“ Ø¢Ù…ÙˆØ²Ø´ SVM...\")\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Ø¯Ù‚Øª SVM\n",
    "svm_train_acc = accuracy_score(y_train, svm_model.predict(X_train))\n",
    "svm_test_acc = accuracy_score(y_test, svm_model.predict(X_test))\n",
    "print(f\"ğŸ¯ Ø¯Ù‚Øª SVM Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´: {svm_train_acc:.2f}\")\n",
    "print(f\"ğŸ¯ Ø¯Ù‚Øª SVM Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª: {svm_test_acc:.2f}\")\n",
    "\n",
    "# Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… Ø¨Ø§ Ú©Ù†ØªØ±Ù„ Overfitting Ø¨Ø§ pruning Ùˆ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡\n",
    "print(\"\\nğŸ“ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… (Ø¨Ø§ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Overfitting)...\")\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    ccp_alpha=0.001,  # pruning\n",
    "    random_state=42\n",
    ")\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "dt_train_acc = accuracy_score(y_train, dt_model.predict(X_train))\n",
    "dt_test_acc = accuracy_score(y_test, dt_model.predict(X_test))\n",
    "print(f\"ğŸŒ³ Ø¯Ù‚Øª Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´: {dt_train_acc:.2f}\")\n",
    "print(f\"ğŸŒ³ Ø¯Ù‚Øª Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª: {dt_test_acc:.2f}\")\n",
    "\n",
    "# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² GridSearchCV Ø¨Ø±Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Random Forest\n",
    "print(\"\\nğŸ” Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† ØªÙ†Ø¸ÛŒÙ…Ø§Øª Random Forest Ø¨Ø§ GridSearch...\")\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Ø¯Ù‚Øª Random Forest\n",
    "rf_train_acc = accuracy_score(y_train, rf_model.predict(X_train))\n",
    "rf_test_acc = accuracy_score(y_test, rf_model.predict(X_test))\n",
    "print(f\"ğŸŒ² Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Random Forest: {grid_search.best_params_}\")\n",
    "print(f\"ğŸŒ² Ø¯Ù‚Øª Random Forest Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´: {rf_train_acc:.2f}\")\n",
    "print(f\"ğŸŒ² Ø¯Ù‚Øª Random Forest Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª: {rf_test_acc:.2f}\")\n",
    "\n",
    "# Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§\n",
    "joblib.dump(svm_model, os.path.join(output_dir, 'svm_model.joblib'))\n",
    "joblib.dump(dt_model, os.path.join(output_dir, 'decision_tree_model.joblib'))\n",
    "joblib.dump(rf_model, os.path.join(output_dir, 'random_forest_model.joblib'))\n",
    "joblib.dump(pca, os.path.join(output_dir, 'pca_transform.joblib'))\n",
    "\n",
    "print(f\"\\nâœ… Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ PCA Ø¯Ø± Ù…Ø³ÛŒØ± {output_dir} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f054a3",
   "metadata": {},
   "source": [
    "# ÙØ§Ø² 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e8416e",
   "metadata": {},
   "source": [
    "### Ù†Ø§Ù… Ø¯Ø§Ø¯Ù† Ú©Ø§Ø±Ø§Ú©ØªØ± Ù‡Ø§ Ø¨Ø§ Ù…Ø¯Ù„ Ù‡Ø§ÛŒ Ø®ÙˆØ¯Ù…ÙˆÙ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cbadd9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "import joblib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da6a8193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1612/1612 [00:08<00:00, 180.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ SVM Ø¯Ø± ÙØ§ÛŒÙ„ output_phase4\\svm_predictions.txt Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Decision Tree Ø¯Ø± ÙØ§ÛŒÙ„ output_phase4\\decision_tree_predictions.txt Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "âœ… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Random Forest Ø¯Ø± ÙØ§ÛŒÙ„ output_phase4\\random_forest_predictions.txt Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ù…Ø³ÛŒØ±Ù‡Ø§\n",
    "input_dir = 'output_phase2.4'\n",
    "model_dir = 'output_phase3.1'\n",
    "output_dir = 'output_phase4'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ PCA\n",
    "svm_model = joblib.load(os.path.join(model_dir, 'svm_model.joblib'))\n",
    "dt_model = joblib.load(os.path.join(model_dir, 'decision_tree_model.joblib'))\n",
    "rf_model = joblib.load(os.path.join(model_dir, 'random_forest_model.joblib'))  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯\n",
    "pca = joblib.load(os.path.join(model_dir, 'pca_transform.joblib'))\n",
    "\n",
    "# Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ HOG\n",
    "image_size = (28, 28)\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø§Ù… Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§\n",
    "label_names = sorted(os.listdir('output_phase3'))\n",
    "label_map = {name: idx for idx, name in enumerate(label_names)}\n",
    "inv_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "def preprocess_image(img):\n",
    "    _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    x, y_, w, h = cv2.boundingRect(binary)\n",
    "    cropped = binary[y_:y_+h, x:x+w]\n",
    "    resized = cv2.resize(cropped, image_size)\n",
    "    return resized\n",
    "\n",
    "# Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ÛŒ Ù†ØªØ§ÛŒØ¬ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…Ø¯Ù„\n",
    "svm_results = []\n",
    "dt_results = []\n",
    "rf_results = []  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯\n",
    "\n",
    "print(\"Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§...\")\n",
    "\n",
    "for img_name in tqdm(os.listdir(input_dir)):\n",
    "    img_path = os.path.join(input_dir, img_name)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"âš ï¸ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† ØªØµÙˆÛŒØ± {img_name} Ø±Ø§ Ø®ÙˆØ§Ù†Ø¯.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        pre_img = preprocess_image(img)\n",
    "        features = hog(pre_img,\n",
    "                       orientations=orientations,\n",
    "                       pixels_per_cell=pixels_per_cell,\n",
    "                       cells_per_block=cells_per_block,\n",
    "                       block_norm='L2-Hys',\n",
    "                       visualize=False)\n",
    "        features_pca = pca.transform([features])\n",
    "\n",
    "        svm_pred = svm_model.predict(features_pca)[0]\n",
    "        dt_pred = dt_model.predict(features_pca)[0]\n",
    "        rf_pred = rf_model.predict(features_pca)[0]  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯\n",
    "\n",
    "        svm_label = inv_label_map.get(svm_pred, \"Unknown\")\n",
    "        dt_label = inv_label_map.get(dt_pred, \"Unknown\")\n",
    "        rf_label = inv_label_map.get(rf_pred, \"Unknown\")  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯\n",
    "\n",
    "        svm_results.append(f\"{img_name}\\t{svm_label}\")\n",
    "        dt_results.append(f\"{img_name}\\t{dt_label}\")\n",
    "        rf_results.append(f\"{img_name}\\t{rf_label}\")  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ {img_name}: {e}\")\n",
    "\n",
    "# Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡\n",
    "svm_output_file = os.path.join(output_dir, 'svm_predictions.txt')\n",
    "dt_output_file = os.path.join(output_dir, 'decision_tree_predictions.txt')\n",
    "rf_output_file = os.path.join(output_dir, 'random_forest_predictions.txt')  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯\n",
    "\n",
    "with open(svm_output_file, 'w', encoding='utf-8') as f:\n",
    "    for line in svm_results:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "with open(dt_output_file, 'w', encoding='utf-8') as f:\n",
    "    for line in dt_results:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "with open(rf_output_file, 'w', encoding='utf-8') as f:  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯\n",
    "    for line in rf_results:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print(f\"\\nâœ… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ SVM Ø¯Ø± ÙØ§ÛŒÙ„ {svm_output_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n",
    "print(f\"âœ… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Decision Tree Ø¯Ø± ÙØ§ÛŒÙ„ {dt_output_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n",
    "print(f\"âœ… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Random Forest Ø¯Ø± ÙØ§ÛŒÙ„ {rf_output_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e974c",
   "metadata": {},
   "source": [
    "### Ù†Ø§Ù… Ø¯Ø§Ø¯Ù† Ø¨Ù‡ ØªØµØ§ÙˆÛŒØ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f353ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ad1c347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ…Ø§Ù… Ø´Ø¯. ØªØµØ§ÙˆÛŒØ± Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ùˆ Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ù…Ø³ÛŒØ±Ù‡Ø§\n",
    "images_dir = \"output_phase2.4\"\n",
    "names_dir = \"output_phase4\"\n",
    "output_dir = \"output_phase4.1\"\n",
    "\n",
    "# Ø³Ø§Ø®ØªÙ† Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Ø®ÙˆØ§Ù†Ø¯Ù† ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ txt Ø¯Ø± Ù¾ÙˆØ´Ù‡ output_phase4\n",
    "for txt_file in os.listdir(names_dir):\n",
    "    if txt_file.endswith(\".txt\"):\n",
    "        model_name = os.path.splitext(txt_file)[0]\n",
    "        model_output_path = os.path.join(output_dir, model_name)\n",
    "        os.makedirs(model_output_path, exist_ok=True)\n",
    "\n",
    "        # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ txt\n",
    "        txt_path = os.path.join(names_dir, txt_file)\n",
    "\n",
    "        # Ø®ÙˆØ§Ù†Ø¯Ù† Ù†Ø§Ù…â€Œ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø§Ø² txt + Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ\n",
    "        with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = [line.strip().replace('\\t', '').replace('/', '_').replace('\\\\', '_') for line in f if line.strip()]\n",
    "\n",
    "        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªØµØ§ÙˆÛŒØ± Ø¨Ù‡ Ù‡Ù…Ø§Ù† ØªØ±ØªÛŒØ¨ Ø¯Ø± Ù¾ÙˆØ´Ù‡ ØªØµØ§ÙˆÛŒØ±\n",
    "        image_files = sorted(os.listdir(images_dir))  # Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø´Ø¯ØŒ ÙÛŒÙ„ØªØ± Ø±ÙˆÛŒ ÙØ±Ù…Øª Ø¨Ú¯Ø°Ø§Ø±\n",
    "        for i, new_name in enumerate(lines):\n",
    "            if i >= len(image_files):\n",
    "                print(f\"ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª Ø¨Ø±Ø§ÛŒ {txt_file}\")\n",
    "                break\n",
    "\n",
    "            original_image_path = os.path.join(images_dir, image_files[i])\n",
    "            extension = os.path.splitext(image_files[i])[1]\n",
    "            clean_name = new_name.strip().replace(\" \", \"_\").replace(\":\", \"-\")  # Ø¨ÛŒØ´ØªØ± Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø¨ÙˆØ¯\n",
    "            new_image_name = f\"{clean_name}{extension}\"\n",
    "            new_image_path = os.path.join(model_output_path, new_image_name)\n",
    "\n",
    "            try:\n",
    "                shutil.copy(original_image_path, new_image_path)\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ú©Ù¾ÛŒ {original_image_path} Ø¨Ù‡ {new_image_path}: {e}\")\n",
    "\n",
    "print(\"âœ… ØªÙ…Ø§Ù… Ø´Ø¯. ØªØµØ§ÙˆÛŒØ± Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ùˆ Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b28ec",
   "metadata": {},
   "source": [
    "### Ù†Ù…Ø§ÛŒØ´ Ú©Ø§Ø±Ø§Ú©ØªØ± Ù‡Ø§ÛŒ Ù¾Ù„Ø§Ú© Ø¨Ù‡ Ø¯Ø± ÛŒÚ© Ø®Ø·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cb3ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27de5ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1612/1612 [00:06<00:00, 264.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù†Ø¯:\n",
      "ğŸ“„ output_phase4.2\\svm_predictions.txt\n",
      "ğŸ“„ output_phase4.2\\dt_predictions.txt\n",
      "ğŸ“„ output_phase4.2\\random_forest_predictions.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Ù…Ø³ÛŒØ±Ù‡Ø§\n",
    "input_dir = 'output_phase2.4'     # ØªØµØ§ÙˆÛŒØ± Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ\n",
    "model_dir = 'output_phase3.1'     # Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ PCA Ø§Ø² ÙØ§Ø² 3\n",
    "output_dir = 'output_phase4.2'      # Ø®Ø±ÙˆØ¬ÛŒ ÙØ§Ø² 4\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ PCA\n",
    "svm_model = joblib.load(os.path.join(model_dir, 'svm_model.joblib'))\n",
    "dt_model = joblib.load(os.path.join(model_dir, 'decision_tree_model.joblib'))\n",
    "rf_model = joblib.load(os.path.join(model_dir, 'random_forest_model.joblib'))  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
    "pca = joblib.load(os.path.join(model_dir, 'pca_transform.joblib'))\n",
    "\n",
    "# Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ HOG\n",
    "image_size = (28, 28)\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø§Ù… Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§\n",
    "label_names = sorted(os.listdir('output_phase3'))\n",
    "label_map = {name: idx for idx, name in enumerate(label_names)}\n",
    "inv_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "def preprocess_image(img):\n",
    "    _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    x, y_, w, h = cv2.boundingRect(binary)\n",
    "    cropped = binary[y_:y_+h, x:x+w]\n",
    "    resized = cv2.resize(cropped, image_size)\n",
    "    return resized\n",
    "\n",
    "# Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§\n",
    "svm_results = defaultdict(list)\n",
    "dt_results = defaultdict(list)\n",
    "rf_results = defaultdict(list)  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
    "\n",
    "print(\"Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§...\")\n",
    "\n",
    "# Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ±ØªÛŒØ¨ ØµØ­ÛŒØ­ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§\n",
    "image_files = sorted(os.listdir(input_dir))\n",
    "\n",
    "for img_name in tqdm(image_files):\n",
    "    img_path = os.path.join(input_dir, img_name)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"âš ï¸ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† ØªØµÙˆÛŒØ± {img_name} Ø±Ø§ Ø®ÙˆØ§Ù†Ø¯.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        plate_id = img_name.split('_')[0]  # Ù…Ø«Ù„ 101 Ø§Ø² \"101_char5.png\"\n",
    "        pre_img = preprocess_image(img)\n",
    "        features = hog(pre_img,\n",
    "                       orientations=orientations,\n",
    "                       pixels_per_cell=pixels_per_cell,\n",
    "                       cells_per_block=cells_per_block,\n",
    "                       block_norm='L2-Hys',\n",
    "                       visualize=False)\n",
    "        features_pca = pca.transform([features])\n",
    "\n",
    "        svm_pred = svm_model.predict(features_pca)[0]\n",
    "        dt_pred = dt_model.predict(features_pca)[0]\n",
    "        rf_pred = rf_model.predict(features_pca)[0]  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
    "\n",
    "        svm_label = inv_label_map.get(svm_pred, \"Unknown\")\n",
    "        dt_label = inv_label_map.get(dt_pred, \"Unknown\")\n",
    "        rf_label = inv_label_map.get(rf_pred, \"Unknown\")  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
    "\n",
    "        svm_results[plate_id].append(svm_label)\n",
    "        dt_results[plate_id].append(dt_label)\n",
    "        rf_results[plate_id].append(rf_label)  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ {img_name}: {e}\")\n",
    "\n",
    "# Ù†ÙˆØ´ØªÙ† Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§\n",
    "svm_output_path = os.path.join(output_dir, 'svm_predictions.txt')\n",
    "dt_output_path = os.path.join(output_dir, 'dt_predictions.txt')\n",
    "rf_output_path = os.path.join(output_dir, 'random_forest_predictions.txt')  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
    "\n",
    "with open(svm_output_path, 'w', encoding='utf-8') as f_svm, \\\n",
    "     open(dt_output_path, 'w', encoding='utf-8') as f_dt, \\\n",
    "     open(rf_output_path, 'w', encoding='utf-8') as f_rf:  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
    "    f_svm.write(\"name,plate\\n\")\n",
    "    f_dt.write(\"name,plate\\n\")\n",
    "    f_rf.write(\"name,plate\\n\")  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
    "\n",
    "    for plate_id in sorted(svm_results.keys(), key=lambda x: int(x)):\n",
    "        svm_line = ','.join([plate_id] + svm_results[plate_id])\n",
    "        dt_line = ','.join([plate_id] + dt_results[plate_id])\n",
    "        rf_line = ','.join([plate_id] + rf_results[plate_id])  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
    "        f_svm.write(svm_line + '\\n')\n",
    "        f_dt.write(dt_line + '\\n')\n",
    "        f_rf.write(rf_line + '\\n')  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
    "\n",
    "print(\"\\nâœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù†Ø¯:\")\n",
    "print(\"ğŸ“„\", svm_output_path)\n",
    "print(\"ğŸ“„\", dt_output_path)\n",
    "print(\"ğŸ“„\", rf_output_path)  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d3f7cd",
   "metadata": {},
   "source": [
    "### ØªØµØ­ÛŒØ­ Ù†Ø§Ù… Ú©Ø§Ø±Ø§Ú©ØªØ± Ù‡Ø§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd9427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be8b14ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ÙØ§ÛŒÙ„ svm_predictions.txt Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø± output_phase4.3\\svm_predictions.txt\n",
      "âœ… ÙØ§ÛŒÙ„ random_forest_predictions.txt Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø± output_phase4.3\\random_forest_predictions.txt\n",
      "âœ… ÙØ§ÛŒÙ„ dt_predictions.txt Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø± output_phase4.3\\dt_predictions.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dir = \"output_phase4.2\"\n",
    "output_dir = \"output_phase4.3\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model_files = {\n",
    "    \"svm\": \"svm_predictions.txt\",\n",
    "    \"random_forest\": \"random_forest_predictions.txt\",\n",
    "    \"dt\": \"dt_predictions.txt\"\n",
    "}\n",
    "\n",
    "def clean_labels_from_file(input_path, output_path):\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as fin, open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        header = fin.readline()\n",
    "        fout.write(header)  # Ù†ÙˆØ´ØªÙ† header Ø¨Ù‡ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "\n",
    "        for line in fin:\n",
    "            parts = line.strip().split(\",\")\n",
    "            name = parts[0]\n",
    "            labels = parts[1:]\n",
    "            cleaned_labels = []\n",
    "            for label in labels:\n",
    "                if '-' in label:\n",
    "                    cleaned_labels.append(label.split('-', 1)[1])\n",
    "                else:\n",
    "                    cleaned_labels.append(label)\n",
    "            fout.write(name + \",\" + \",\".join(cleaned_labels) + \"\\n\")\n",
    "\n",
    "for model_name, filename in model_files.items():\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    if os.path.exists(input_path):\n",
    "        clean_labels_from_file(input_path, output_path)\n",
    "        print(f\"âœ… ÙØ§ÛŒÙ„ {filename} Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø± {output_path}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ ÙØ§ÛŒÙ„ {filename} Ø¯Ø± Ù…Ø³ÛŒØ± {input_dir} ÛŒØ§ÙØª Ù†Ø´Ø¯!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be37007",
   "metadata": {},
   "source": [
    "# ÙØ§Ø² 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c287e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae9afc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 8 samples after filtering.\n",
      "\n",
      "ğŸ” SVM Evaluation:\n",
      "  âœ… Accuracy : 23.17%\n",
      "  ğŸ¯ Precision: 7.65%\n",
      "  ğŸ” Recall   : 6.97%\n",
      "Decision Tree: 6 samples after filtering.\n",
      "\n",
      "ğŸ” DT Evaluation:\n",
      "  âœ… Accuracy : 12.66%\n",
      "  ğŸ¯ Precision: 8.69%\n",
      "  ğŸ” Recall   : 7.44%\n",
      "Random Forest: 9 samples after filtering.\n",
      "\n",
      "ğŸ” RANDOM_FOREST Evaluation:\n",
      "  âœ… Accuracy : 7.78%\n",
      "  ğŸ¯ Precision: 1.79%\n",
      "  ğŸ” Recall   : 1.39%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§\n",
    "svm_pred_path = \"output_phase4.3/svm_predictions.txt\"\n",
    "dt_pred_path = \"output_phase4.3/dt_predictions.txt\"\n",
    "rf_pred_path = \"output_phase4.3/random_forest_predictions.txt\"\n",
    "label_path = \"Plates2/plate_labels.txt\"\n",
    "output_dir = \"output_phase5\"\n",
    "\n",
    "# Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ØªØ§Ø¨Ø¹ Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§\n",
    "def read_labels(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        return [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
    "y_true = read_labels(label_path)\n",
    "y_pred_svm = read_labels(svm_pred_path)\n",
    "y_pred_dt = read_labels(dt_pred_path)\n",
    "y_pred_rf = read_labels(rf_pred_path)\n",
    "\n",
    "# ÙÛŒÙ„ØªØ± Ù¾Ù„Ø§Ú©â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø·ÙˆÙ„ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ Ø¨Ø±Ø§Ø¨Ø± Ø§Ø³Øª\n",
    "def filter_matching_length(true_labels, pred_labels):\n",
    "    filtered_true = []\n",
    "    filtered_pred = []\n",
    "    for t, p in zip(true_labels, pred_labels):\n",
    "        if len(t) == len(p):\n",
    "            filtered_true.append(t)\n",
    "            filtered_pred.append(p)\n",
    "    return filtered_true, filtered_pred\n",
    "\n",
    "# ØªØ¨Ø¯ÛŒÙ„ Ù„ÛŒØ³Øª Ø¨Ù‡ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡\n",
    "def flatten(chars_list):\n",
    "    return [char for plate in chars_list for char in plate]\n",
    "\n",
    "# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„\n",
    "def evaluate_model(y_true_chars, y_pred_chars, model_name):\n",
    "    acc = accuracy_score(y_true_chars, y_pred_chars)\n",
    "    prec = precision_score(y_true_chars, y_pred_chars, average='macro', zero_division=0)\n",
    "    rec = recall_score(y_true_chars, y_pred_chars, average='macro', zero_division=0)\n",
    "    cm = confusion_matrix(y_true_chars, y_pred_chars)\n",
    "\n",
    "    # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§\n",
    "    with open(f\"{output_dir}/{model_name}_metrics.txt\", \"w\") as f:\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
    "        f.write(f\"Precision: {prec:.4f}\\n\")\n",
    "        f.write(f\"Recall: {rec:.4f}\\n\")\n",
    "\n",
    "    # Ø±Ø³Ù… confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "    plt.title(f\"Confusion Matrix - {model_name.upper()}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/{model_name}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Ú†Ø§Ù¾ Ø¯Ø±ØµØ¯Ù‡Ø§ Ø¯Ø± ØªØ±Ù…ÛŒÙ†Ø§Ù„\n",
    "    print(f\"\\nğŸ” {model_name.upper()} Evaluation:\")\n",
    "    print(f\"  âœ… Accuracy : {acc * 100:.2f}%\")\n",
    "    print(f\"  ğŸ¯ Precision: {prec * 100:.2f}%\")\n",
    "    print(f\"  ğŸ” Recall   : {rec * 100:.2f}%\")\n",
    "\n",
    "# ===========================\n",
    "# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ SVM\n",
    "y_true_svm, y_pred_svm_filtered = filter_matching_length(y_true, y_pred_svm)\n",
    "print(f\"SVM: {len(y_true_svm)} samples after filtering.\")\n",
    "y_true_chars_svm = flatten(y_true_svm)\n",
    "y_pred_svm_chars = flatten(y_pred_svm_filtered)\n",
    "\n",
    "if y_true_chars_svm and y_pred_svm_chars:\n",
    "    evaluate_model(y_true_chars_svm, y_pred_svm_chars, \"svm\")\n",
    "else:\n",
    "    print(\"âš ï¸ SVM: No valid data after filtering for matching lengths.\")\n",
    "\n",
    "# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Decision Tree\n",
    "y_true_dt, y_pred_dt_filtered = filter_matching_length(y_true, y_pred_dt)\n",
    "print(f\"Decision Tree: {len(y_true_dt)} samples after filtering.\")\n",
    "y_true_chars_dt = flatten(y_true_dt)\n",
    "y_pred_dt_chars = flatten(y_pred_dt_filtered)\n",
    "\n",
    "if y_true_chars_dt and y_pred_dt_chars:\n",
    "    evaluate_model(y_true_chars_dt, y_pred_dt_chars, \"dt\")\n",
    "else:\n",
    "    print(\"âš ï¸ Decision Tree: No valid data after filtering for matching lengths.\")\n",
    "\n",
    "# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Random Forest\n",
    "y_true_rf, y_pred_rf_filtered = filter_matching_length(y_true, y_pred_rf)\n",
    "print(f\"Random Forest: {len(y_true_rf)} samples after filtering.\")\n",
    "y_true_chars_rf = flatten(y_true_rf)\n",
    "y_pred_rf_chars = flatten(y_pred_rf_filtered)\n",
    "\n",
    "if y_true_chars_rf and y_pred_rf_chars:\n",
    "    evaluate_model(y_true_chars_rf, y_pred_rf_chars, \"random_forest\")\n",
    "else:\n",
    "    print(\"âš ï¸ Random Forest: No valid data after filtering for matching lengths.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
