{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8397fdda",
   "metadata": {},
   "source": [
    "# به نام خدا"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81215f",
   "metadata": {},
   "source": [
    "# فاز 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "259fd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49cd300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "پردازش تصاویر: 100%|██████████| 217/217 [00:00<00:00, 301.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "پردازش فاز اول با موفقیت به پایان رسید. پلاک‌های استخراج شده در پوشه 'output_phase1' ذخیره شدند.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def parse_annotation(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    plates = []\n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text\n",
    "        if name.lower() == 'vehicle plate':\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = int(bndbox.find('xmin').text)\n",
    "            ymin = int(bndbox.find('ymin').text)\n",
    "            xmax = int(bndbox.find('xmax').text)\n",
    "            ymax = int(bndbox.find('ymax').text)\n",
    "            plates.append((xmin, ymin, xmax, ymax))\n",
    "    \n",
    "    return plates\n",
    "\n",
    "def extract_plates(image_path, annotation_path, output_path):\n",
    "    # خواندن تصویر\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"خطا در خواندن تصویر: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # خواندن آنوتیشن‌ها\n",
    "    plates = parse_annotation(annotation_path)\n",
    "    if not plates:\n",
    "        print(f\"هیچ پلاکی در فایل آنوتیشن یافت نشد: {annotation_path}\")\n",
    "        return\n",
    "    \n",
    "    # استخراج و ذخیره هر پلاک\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    for i, (xmin, ymin, xmax, ymax) in enumerate(plates):\n",
    "        plate_img = image[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        # ذخیره پلاک استخراج شده\n",
    "        output_file = os.path.join(output_path, f\"{base_name}.png\")\n",
    "        cv2.imwrite(output_file, plate_img)\n",
    "\n",
    "def process_dataset(base_dir, output_dir):\n",
    "    # مسیرهای ورودی\n",
    "    images_dir = os.path.join(base_dir, \"Vehicle Plates\", \"Vehicle Plates\")\n",
    "    annotations_dir = os.path.join(base_dir, \"Vehicle Plates annotations\", \"Vehicle Plates annotations\")\n",
    "    \n",
    "    # بررسی وجود پوشه‌ها\n",
    "    if not os.path.exists(images_dir):\n",
    "        print(f\"پوشه تصاویر یافت نشد: {images_dir}\")\n",
    "        return\n",
    "    if not os.path.exists(annotations_dir):\n",
    "        print(f\"پوشه آنوتیشن‌ها یافت نشد: {annotations_dir}\")\n",
    "        return\n",
    "    \n",
    "    # لیست تمام فایل‌های تصویر\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # ایجاد پوشه خروجی اگر وجود نداشته باشد\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # پردازش هر تصویر با نوار پیشرفت\n",
    "    for img_file in tqdm(image_files, desc=\"پردازش تصاویر\"):\n",
    "        base_name = os.path.splitext(img_file)[0]\n",
    "        image_path = os.path.join(images_dir, img_file)\n",
    "        annotation_path = os.path.join(annotations_dir, f\"{base_name}.xml\")\n",
    "        \n",
    "        if os.path.exists(annotation_path):\n",
    "            extract_plates(image_path, annotation_path, output_dir)\n",
    "        else:\n",
    "            print(f\"فایل آنوتیشن یافت نشد: {annotation_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # مسیرهای ورودی و خروجی\n",
    "    base_dir = \"Plates2\"\n",
    "    output_dir = \"output_phase1\"\n",
    "    \n",
    "    # اجرای پردازش\n",
    "    process_dataset(base_dir, output_dir)\n",
    "    \n",
    "    print(f\"پردازش فاز اول با موفقیت به پایان رسید. پلاک‌های استخراج شده در پوشه '{output_dir}' ذخیره شدند.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c34b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "029a3767",
   "metadata": {},
   "source": [
    "# فاز 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f5693a",
   "metadata": {},
   "source": [
    "### درست کردن کجی و سیاه سفید کردن"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f24242e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ اصلاح زاویه با ترکیب minAreaRect + Hough انجام شد.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_folder = 'output_phase1'\n",
    "output_folder = 'output_phase2'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "def angle_from_min_area_rect(thresh):\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    largest = max(contours, key=cv2.contourArea)\n",
    "    rect = cv2.minAreaRect(largest)\n",
    "    angle = rect[-1]\n",
    "    if angle < -45:\n",
    "        angle += 90\n",
    "    elif angle > 45:\n",
    "        angle -= 90\n",
    "    return angle\n",
    "\n",
    "def angle_from_hough(gray):\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, minLineLength=30, maxLineGap=10)\n",
    "    if lines is None:\n",
    "        return None\n",
    "    angles = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "        if -45 < angle < 45:\n",
    "            angles.append(angle)\n",
    "    if not angles:\n",
    "        return None\n",
    "    return np.median(angles)\n",
    "\n",
    "def correct_skew_combined(gray_image, angle_threshold=3):\n",
    "    # Preprocess\n",
    "    _, thresh = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    thresh = 255 - thresh\n",
    "\n",
    "    # Step 1: try minAreaRect\n",
    "    angle = angle_from_min_area_rect(thresh)\n",
    "\n",
    "    # Step 2: fallback to HoughLines if angle too small or None\n",
    "    if angle is None or abs(angle) < angle_threshold:\n",
    "        angle = angle_from_hough(gray_image)\n",
    "\n",
    "    # اگر همچنان زاویه معنادار نبود، تصویر را برگردان\n",
    "    if angle is None or abs(angle) < angle_threshold:\n",
    "        return gray_image\n",
    "\n",
    "    # Rotate\n",
    "    (h, w) = gray_image.shape\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(gray_image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "# پردازش همه تصاویر\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "        path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        corrected = correct_skew_combined(gray)\n",
    "\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, corrected)\n",
    "\n",
    "print(\"✅ اصلاح زاویه با ترکیب minAreaRect + Hough انجام شد.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be0ea65",
   "metadata": {},
   "source": [
    "### کات دادن یک هشتم اول پلاک"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95457256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "پردازش تمام شد.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# مسیرهای ورودی و خروجی\n",
    "input_dir = 'output_phase2'\n",
    "output_dir = 'output_phase2.1'\n",
    "\n",
    "# ساخت پوشه خروجی اگر وجود نداشت\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# پردازش هر تصویر در پوشه ورودی\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tif')):\n",
    "        img_path = os.path.join(input_dir, filename)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # ابعاد تصویر\n",
    "        width, height = img.size\n",
    "\n",
    "        # عرض هر تکه\n",
    "        slice_width = width // 8\n",
    "\n",
    "        # برش تصویر: حذف تیکه اول (از x=0 تا x=slice_width)\n",
    "        # نگه داشتن بخش باقی‌مانده (از x=slice_width تا x=width)\n",
    "        cropped_img = img.crop((slice_width, 0, width, height))\n",
    "\n",
    "        # ذخیره تصویر خروجی\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cropped_img.save(output_path)\n",
    "\n",
    "print(\"پردازش تمام شد.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea3df5",
   "metadata": {},
   "source": [
    "### باینری کردن عکس ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd13ae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "پردازش پیشرفته و تبدیل به باینری با حفظ جزئیات انجام شد.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_folder = 'output_phase2.1'\n",
    "output_folder = 'output_phase2.2'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # 1. نویززدایی با فیلتر غیرمحلی (Non-local Means)\n",
    "        denoised = cv2.fastNlMeansDenoising(img, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "        \n",
    "        # 2. افزایش کنتراست با CLAHE (بهتر از اکولایزیشن ساده)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        contrast_enhanced = clahe.apply(denoised)\n",
    "        \n",
    "        # 3. فیلتر گوسی برای نرم کردن (با هسته کوچکتر)\n",
    "        blurred = cv2.GaussianBlur(contrast_enhanced, (3,3), 0)\n",
    "        \n",
    "        # 4. آستانه‌گذاری تطبیقی با پارامترهای بهینه‌تر\n",
    "        binary_img = cv2.adaptiveThreshold(\n",
    "            blurred,\n",
    "            255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY_INV,\n",
    "            11,  # اندازه بلوک - باید کوچکتر باشد برای حفظ جزئیات\n",
    "            2    # مقدار ثابت - کاهش یافته برای جلوگیری از سیاه شدن نواحی روشن\n",
    "        )\n",
    "        \n",
    "        # 5. مورفولوژی برای حذف نویزهای کوچک\n",
    "        kernel = np.ones((2,2), np.uint8)\n",
    "        processed = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # معکوس کردن تصویر برای داشتن متن سفید روی پس زمینه سیاه\n",
    "        final_img = cv2.bitwise_not(processed)\n",
    "        \n",
    "        # ذخیره خروجی\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, final_img)\n",
    "\n",
    "print(\"پردازش پیشرفته و تبدیل به باینری با حفظ جزئیات انجام شد.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e54b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "پردازش حرفه‌ای با حفظ حداکثر کیفیت انجام شد.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_folder = 'output_phase2.1'\n",
    "output_folder = 'output_phase2.2'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # 1. پیش‌پردازش اولیه با حفظ جزئیات\n",
    "        denoised = cv2.fastNlMeansDenoising(img, h=5, templateWindowSize=7, searchWindowSize=21)\n",
    "        \n",
    "        # 2. افزایش کنتراست هوشمند\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(12,12))\n",
    "        contrast_enhanced = clahe.apply(denoised)\n",
    "        \n",
    "        # 3. بهبود لبه‌ها با فیلتر ویژه\n",
    "        blurred = cv2.bilateralFilter(contrast_enhanced, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "        \n",
    "        # 4. روش ترکیبی آستانه‌گذاری\n",
    "        # مرحله اول: Adaptive Threshold\n",
    "        binary_adaptive = cv2.adaptiveThreshold(\n",
    "            blurred,\n",
    "            255,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY_INV,\n",
    "            blockSize=9,\n",
    "            C=2\n",
    "        )\n",
    "        \n",
    "        # مرحله دوم: Otsu Threshold\n",
    "        _, binary_otsu = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # مرحله سوم: ترکیب با وزن‌دهی\n",
    "        combined = cv2.addWeighted(binary_adaptive, 0.7, binary_otsu, 0.3, 0)\n",
    "        \n",
    "        # 5. بهبود نهایی با تکنیک Super-Resolution (اختیاری)\n",
    "        # اگر opencv با contrib نصب باشد:\n",
    "        # super_res = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "        # super_res.readModel('EDSR_x4.pb')\n",
    "        # super_res.setModel('edsr', 4)\n",
    "        # final_img = super_res.upsample(combined)\n",
    "        \n",
    "        # 6. ذخیره نتیجه\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, cv2.bitwise_not(combined))\n",
    "\n",
    "print(\"پردازش حرفه‌ای با حفظ حداکثر کیفیت انجام شد.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ef098",
   "metadata": {},
   "source": [
    "### در اوردن کاراکتر های هر عکس"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "657e64f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 1.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 10.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 100.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 101.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 102.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 103.png: 2 کاراکتر نهایی ذخیره شد.\n",
      "✅ 104.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 105.png: 10 کاراکتر نهایی ذخیره شد.\n",
      "✅ 106.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 107.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 108.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 109.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 11.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 110.png: 10 کاراکتر نهایی ذخیره شد.\n",
      "✅ 111.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 112.png: 3 کاراکتر نهایی ذخیره شد.\n",
      "✅ 113.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 114.png: 11 کاراکتر نهایی ذخیره شد.\n",
      "✅ 115.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 116.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 117.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 118.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 119.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 12.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 120.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 121.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 122.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 123.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 124.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 125.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 126.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 127.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 128.png: 1 کاراکتر نهایی ذخیره شد.\n",
      "✅ 129.png: 3 کاراکتر نهایی ذخیره شد.\n",
      "✅ 13.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 130.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 131.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 132.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 133.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 134.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 135.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 136.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 137.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 138.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 139.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 14.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 140.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 141.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 142.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 143.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 144.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 145.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 146.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 147.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 148.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 149.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 15.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 150.png: 3 کاراکتر نهایی ذخیره شد.\n",
      "✅ 151.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 152.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 153.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 154.png: 3 کاراکتر نهایی ذخیره شد.\n",
      "✅ 155.png: 2 کاراکتر نهایی ذخیره شد.\n",
      "✅ 156.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 157.png: 2 کاراکتر نهایی ذخیره شد.\n",
      "✅ 158.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 159.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 16.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 160.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 161.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 162.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 163.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 164.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 165.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 166.png: 3 کاراکتر نهایی ذخیره شد.\n",
      "✅ 167.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 168.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 169.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 17.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 170.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 171.png: 2 کاراکتر نهایی ذخیره شد.\n",
      "✅ 172.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 173.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 174.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 175.png: 10 کاراکتر نهایی ذخیره شد.\n",
      "✅ 176.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 177.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 178.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 179.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 18.png: 3 کاراکتر نهایی ذخیره شد.\n",
      "✅ 180.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 181.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 182.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 183.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 184.png: 1 کاراکتر نهایی ذخیره شد.\n",
      "✅ 185.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 186.png: 3 کاراکتر نهایی ذخیره شد.\n",
      "✅ 187.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 188.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 189.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 19.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 190.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 191.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 192.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 193.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 194.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 195.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 196.png: 2 کاراکتر نهایی ذخیره شد.\n",
      "✅ 197.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 198.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 199.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 2.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 20.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 200.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 201.png: 1 کاراکتر نهایی ذخیره شد.\n",
      "✅ 202.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 203.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 204.png: 0 کاراکتر نهایی ذخیره شد.\n",
      "✅ 205.png: 10 کاراکتر نهایی ذخیره شد.\n",
      "✅ 206.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 207.png: 3 کاراکتر نهایی ذخیره شد.\n",
      "✅ 208.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 209.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 21.png: 10 کاراکتر نهایی ذخیره شد.\n",
      "✅ 210.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 211.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 212.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 213.png: 10 کاراکتر نهایی ذخیره شد.\n",
      "✅ 214.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 215.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 216.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 217.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 22.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 23.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 24.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 25.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 26.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 27.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 28.png: 10 کاراکتر نهایی ذخیره شد.\n",
      "✅ 29.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 3.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 30.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 31.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 32.png: 11 کاراکتر نهایی ذخیره شد.\n",
      "✅ 33.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 34.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 35.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 36.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 37.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 38.png: 10 کاراکتر نهایی ذخیره شد.\n",
      "✅ 39.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 4.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 40.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 41.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 42.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 43.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 44.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 45.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 46.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 47.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 48.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 49.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 5.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 50.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 51.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 52.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 53.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 54.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 55.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 56.png: 1 کاراکتر نهایی ذخیره شد.\n",
      "✅ 57.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 58.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 59.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 6.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 60.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 61.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 62.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 63.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 64.png: 3 کاراکتر نهایی ذخیره شد.\n",
      "✅ 65.png: 3 کاراکتر نهایی ذخیره شد.\n",
      "✅ 66.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 67.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 68.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 69.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 7.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 70.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 71.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 72.png: 12 کاراکتر نهایی ذخیره شد.\n",
      "✅ 73.png: 10 کاراکتر نهایی ذخیره شد.\n",
      "✅ 74.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 75.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 76.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 77.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 78.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 79.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 8.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 80.png: 10 کاراکتر نهایی ذخیره شد.\n",
      "✅ 81.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 82.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 83.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 84.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 85.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 86.png: 9 کاراکتر نهایی ذخیره شد.\n",
      "✅ 87.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 88.png: 12 کاراکتر نهایی ذخیره شد.\n",
      "✅ 89.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 9.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 90.png: 3 کاراکتر نهایی ذخیره شد.\n",
      "✅ 91.png: 2 کاراکتر نهایی ذخیره شد.\n",
      "✅ 92.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 93.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 94.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 95.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 96.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 97.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 98.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 99.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "🎯 پردازش کامل شد - دقت بالا و تعداد بیشتر.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_folder = \"output_phase2.2\"\n",
    "output_folder = \"output_phase2.3\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(input_folder, filename)\n",
    "    img_original = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img_original is None:\n",
    "        print(f\"⛔ نمی‌توان تصویر {filename} را خواند.\")\n",
    "        continue\n",
    "\n",
    "    # بزرگنمایی ×3 برای حفظ جزئیات\n",
    "    scale = 3\n",
    "    img_highres = cv2.resize(img_original, (img_original.shape[1]*scale, img_original.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # فیلتر گوسی برای کاهش نویز\n",
    "    img_blur = cv2.GaussianBlur(img_highres, (3, 3), 0)\n",
    "\n",
    "    # آستانه‌گذاری تطبیقی برای تطبیق با نورهای غیر یکنواخت\n",
    "    img_bin = cv2.adaptiveThreshold(\n",
    "        img_blur, 255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        15, 8\n",
    "    )\n",
    "\n",
    "    # حذف نویزهای ریز\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    img_bin = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # پیدا کردن تمام کانتورها (نه فقط خارجی)\n",
    "    contours, _ = cv2.findContours(img_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "\n",
    "    if len(bounding_boxes) == 0:\n",
    "        continue\n",
    "\n",
    "    heights = [h for (_, _, _, h) in bounding_boxes]\n",
    "    widths = [w for (_, _, w, _) in bounding_boxes]\n",
    "    mean_height = np.mean(heights)\n",
    "    mean_width = np.mean(widths)\n",
    "\n",
    "    filtered_boxes = []\n",
    "    for x, y, w, h in bounding_boxes:\n",
    "        aspect_ratio = h / float(w + 1e-5)\n",
    "        if w < 6 or h < 15:\n",
    "            continue\n",
    "        if h < 0.4 * mean_height or h > 2.2 * mean_height:\n",
    "            continue\n",
    "        if w > 3.0 * mean_width:\n",
    "            continue\n",
    "        if not (0.5 < aspect_ratio < 7.0):\n",
    "            continue\n",
    "\n",
    "        # بررسی چگالی پیکسل سفید (برای حذف نویز)\n",
    "        roi = img_bin[y:y + h, x:x + w]\n",
    "        white_ratio = np.sum(roi == 255) / (roi.shape[0] * roi.shape[1])\n",
    "        if white_ratio < 0.05 or white_ratio > 0.9:\n",
    "            continue\n",
    "\n",
    "        filtered_boxes.append((x, y, w, h))\n",
    "\n",
    "    # مرتب‌سازی از چپ به راست\n",
    "    filtered_boxes = sorted(filtered_boxes, key=lambda b: b[0])\n",
    "    pad = 6\n",
    "    count = 0\n",
    "\n",
    "    for i, (x, y, w, h) in enumerate(filtered_boxes):\n",
    "        x_new = max(x - pad, 0)\n",
    "        y_new = max(y - pad, 0)\n",
    "        w_new = min(w + 2 * pad, img_highres.shape[1] - x_new)\n",
    "        h_new = min(h + 2 * pad, img_highres.shape[0] - y_new)\n",
    "\n",
    "        char_img = img_highres[y_new:y_new + h_new, x_new:x_new + w_new]\n",
    "\n",
    "        # resize و شارپ‌سازی\n",
    "        char_img_resized = cv2.resize(char_img, (64, 128), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        kernel_sharp = np.array([[0, -1, 0],\n",
    "                                 [-1, 5, -1],\n",
    "                                 [0, -1, 0]])\n",
    "        char_img_resized = cv2.filter2D(char_img_resized, -1, kernel_sharp)\n",
    "\n",
    "        out_name = f\"{os.path.splitext(filename)[0]}_char{count + 1}.png\"\n",
    "        cv2.imwrite(os.path.join(output_folder, out_name), char_img_resized)\n",
    "        count += 1\n",
    "\n",
    "    print(f\"✅ {filename}: {count} کاراکتر نهایی ذخیره شد.\")\n",
    "\n",
    "print(\"🎯 پردازش کامل شد - دقت بالا و تعداد بیشتر.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f62bb93",
   "metadata": {},
   "source": [
    "### تنظیم سایز تصاویر"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df9a3625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1464/1464 [00:00<00:00, 1732.57it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# مسیرها\n",
    "input_dir = 'output_phase2.3'\n",
    "output_dir = 'output_phase2.4'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def clean_and_center_image(img, size=(28, 28)):\n",
    "    # تبدیل به خاکستری اگر رنگی بود\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # باینری کردن (متن سیاه، زمینه سفید)\n",
    "    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # حذف نویز با Morphology\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    clean = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "    # پیدا کردن بزرگ‌ترین کانتور (کاراکتر اصلی)\n",
    "    contours, _ = cv2.findContours(clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return np.ones(size, dtype=np.uint8) * 255  # برگرد تصویر سفید خالی\n",
    "\n",
    "    # انتخاب بزرگ‌ترین کانتور\n",
    "    main_contour = max(contours, key=cv2.contourArea)\n",
    "    mask = np.zeros_like(clean)\n",
    "    cv2.drawContours(mask, [main_contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    # فقط کاراکتر اصلی نگه داشته بشه\n",
    "    isolated = cv2.bitwise_and(clean, mask)\n",
    "\n",
    "    # کراپ به اطراف کاراکتر\n",
    "    x, y, w, h = cv2.boundingRect(main_contour)\n",
    "    char_img = isolated[y:y+h, x:x+w]\n",
    "\n",
    "    # ریسایز با حفظ نسبت\n",
    "    h_new, w_new = char_img.shape\n",
    "    scale = min((size[0] - 4) / h_new, (size[1] - 4) / w_new)\n",
    "    char_resized = cv2.resize(char_img, (int(w_new * scale), int(h_new * scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # قرار دادن وسط تصویر سفید\n",
    "    final_img = np.ones(size, dtype=np.uint8) * 255\n",
    "    h_final, w_final = char_resized.shape\n",
    "    y_offset = (size[0] - h_final) // 2\n",
    "    x_offset = (size[1] - w_final) // 2\n",
    "    final_img[y_offset:y_offset+h_final, x_offset:x_offset+w_final] = 255 - char_resized  # برعکسش کنیم چون اینورت شده بود\n",
    "\n",
    "    return final_img\n",
    "\n",
    "# پردازش تصاویر\n",
    "for filename in tqdm(os.listdir(input_dir)):\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    img = cv2.imread(input_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    cleaned_img = clean_and_center_image(img)\n",
    "    cv2.imwrite(output_path, cleaned_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3321b95",
   "metadata": {},
   "source": [
    "# فاز 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ac998",
   "metadata": {},
   "source": [
    "### آماده سازی داده ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0435894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adbf1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_dir = 'alpha'\n",
    "output_dir = 'output_phase3'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for folder_name in os.listdir(input_dir):\n",
    "    input_folder_path = os.path.join(input_dir, folder_name)\n",
    "    \n",
    "    if os.path.isdir(input_folder_path):\n",
    "        output_folder_path = os.path.join(output_dir, folder_name)\n",
    "        os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "        for img_name in os.listdir(input_folder_path):\n",
    "            input_img_path = os.path.join(input_folder_path, img_name)\n",
    "            output_img_path = os.path.join(output_folder_path, img_name)\n",
    "\n",
    "            try:\n",
    "                with Image.open(input_img_path) as img:\n",
    "                    resized_img = img.resize((28, 28), Image.LANCZOS)  # ← الگوریتم بهتر\n",
    "                    resized_img.save(output_img_path)\n",
    "            except Exception as e:\n",
    "                print(f\"خطا در پردازش عکس {input_img_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c4f97",
   "metadata": {},
   "source": [
    "### اموزش مدل"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb049cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage.feature import hog\n",
    "import joblib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c2ca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "در حال پردازش تصاویر...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:01<00:00, 26.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 مجموع نمونه‌ها (شامل نسخه‌های چرخش‌دار): 8598\n",
      "⚙️ در حال اعمال PCA برای کاهش بعد ویژگی‌ها...\n",
      "\n",
      "🎓 آموزش SVM...\n",
      "🎯 دقت SVM: 0.87\n",
      "\n",
      "🎓 آموزش درخت تصمیم...\n",
      "🌳 دقت درخت تصمیم: 0.64\n",
      "\n",
      "✅ مدل‌ها و PCA در پوشه output_phase3.1 ذخیره شدند.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_dir = 'output_phase3'\n",
    "output_dir = 'output_phase3.1'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "image_size = (28, 28)\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "label_names = sorted(os.listdir(input_dir))\n",
    "label_map = {name: idx for idx, name in enumerate(label_names)}\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # تبدیل به سیاه و سفید\n",
    "    _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # حذف فضای اضافی\n",
    "    x, y_, w, h = cv2.boundingRect(binary)\n",
    "    cropped = binary[y_:y_+h, x:x+w]\n",
    "\n",
    "    # تغییر اندازه\n",
    "    resized = cv2.resize(cropped, image_size)\n",
    "    return resized\n",
    "\n",
    "def augment_image(img):\n",
    "    rows, cols = img.shape\n",
    "    angle = np.random.uniform(-10, 10)\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1.0)\n",
    "    return cv2.warpAffine(img, M, (cols, rows), borderValue=255)\n",
    "\n",
    "print(\"در حال پردازش تصاویر...\")\n",
    "\n",
    "for label_name in tqdm(label_names):\n",
    "    folder_path = os.path.join(input_dir, label_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            # پردازش اصلی\n",
    "            pre_img = preprocess_image(img)\n",
    "\n",
    "            # استخراج ویژگی اصلی\n",
    "            features = hog(pre_img,\n",
    "                           orientations=orientations,\n",
    "                           pixels_per_cell=pixels_per_cell,\n",
    "                           cells_per_block=cells_per_block,\n",
    "                           block_norm='L2-Hys',\n",
    "                           visualize=False)\n",
    "            X.append(features)\n",
    "            y.append(label_map[label_name])\n",
    "\n",
    "            # Augmented نسخه چرخش‌دار\n",
    "            aug_img = augment_image(pre_img)\n",
    "            features_aug = hog(aug_img,\n",
    "                               orientations=orientations,\n",
    "                               pixels_per_cell=pixels_per_cell,\n",
    "                               cells_per_block=cells_per_block,\n",
    "                               block_norm='L2-Hys',\n",
    "                               visualize=False)\n",
    "            X.append(features_aug)\n",
    "            y.append(label_map[label_name])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ خطا در پردازش {img_path}: {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"\\n📊 مجموع نمونه‌ها (شامل نسخه‌های چرخش‌دار): {X.shape[0]}\")\n",
    "\n",
    "# کاهش ابعاد با PCA\n",
    "print(\"⚙️ در حال اعمال PCA برای کاهش بعد ویژگی‌ها...\")\n",
    "pca = PCA(n_components=50)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# تقسیم آموزش/تست\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# آموزش SVM\n",
    "print(\"\\n🎓 آموزش SVM...\")\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_acc = accuracy_score(y_test, svm_model.predict(X_test))\n",
    "print(f\"🎯 دقت SVM: {svm_acc:.2f}\")\n",
    "\n",
    "# آموزش Decision Tree\n",
    "print(\"\\n🎓 آموزش درخت تصمیم...\")\n",
    "dt_model = DecisionTreeClassifier(max_depth=15)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_acc = accuracy_score(y_test, dt_model.predict(X_test))\n",
    "print(f\"🌳 دقت درخت تصمیم: {dt_acc:.2f}\")\n",
    "\n",
    "# ذخیره مدل‌ها و PCA\n",
    "joblib.dump(svm_model, os.path.join(output_dir, 'svm_model.joblib'))\n",
    "joblib.dump(dt_model, os.path.join(output_dir, 'decision_tree_model.joblib'))\n",
    "joblib.dump(pca, os.path.join(output_dir, 'pca_transform.joblib'))\n",
    "\n",
    "print(f\"\\n✅ مدل‌ها و PCA در پوشه {output_dir} ذخیره شدند.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f054a3",
   "metadata": {},
   "source": [
    "# فاز 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0f71f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ نتایج در output_phase4\\results.txt ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "\n",
    "# مسیرها\n",
    "input_folder = 'output_phase2.4'\n",
    "model_folder = 'output_phase3.2'\n",
    "output_folder = 'output_phase4'\n",
    "\n",
    "# ایجاد پوشه خروجی\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# بارگذاری مدل‌ها\n",
    "svm_model = load(os.path.join(model_folder, 'svm_model.joblib'))\n",
    "tree_model = load(os.path.join(model_folder, 'tree_model.joblib'))\n",
    "\n",
    "# مشخص کردن ابعاد مورد انتظار مدل\n",
    "expected_features = svm_model.n_features_in_\n",
    "img_width = 42\n",
    "img_height = expected_features // img_width  # مثلاً 2352 // 42 = 56\n",
    "\n",
    "# پردازش تصاویر و پیش‌بینی\n",
    "results = []\n",
    "\n",
    "for filename in sorted(os.listdir(input_folder)):\n",
    "    if not filename.lower().endswith('.png'):\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(input_folder, filename)\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"نمی‌توان تصویر را بخوانم: {filepath}\")\n",
    "        continue\n",
    "\n",
    "    # تغییر اندازه به اندازه مورد انتظار مدل\n",
    "    resized = cv2.resize(img, (img_width, img_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # تبدیل به بردار ویژگی\n",
    "    features = resized.flatten().reshape(1, -1)\n",
    "\n",
    "    # پیش‌بینی با دو مدل\n",
    "    svm_pred = svm_model.predict(features)[0]\n",
    "    tree_pred = tree_model.predict(features)[0]\n",
    "\n",
    "    # ذخیره نتیجه\n",
    "    results.append((filename, svm_pred, tree_pred))\n",
    "\n",
    "# ذخیره در فایل\n",
    "output_file = os.path.join(output_folder, 'results.txt')\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write('filename\\tSVM_prediction\\tDecisionTree_prediction\\n')\n",
    "    for filename, svm_pred, tree_pred in results:\n",
    "        f.write(f\"{filename}\\t{svm_pred}\\t{tree_pred}\\n\")\n",
    "\n",
    "print(f\"✅ نتایج در {output_file} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be37007",
   "metadata": {},
   "source": [
    "# فاز 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44c3e869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ارزیابی مدل‌ها تکمیل شد.\n",
      "SVM Accuracy: 0.0000\n",
      "Decision Tree Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# مسیر فایل نتایج فاز ۴\n",
    "input_txt_path = \"output_phase4/results.txt\"\n",
    "\n",
    "# بررسی وجود فایل\n",
    "if not os.path.exists(input_txt_path):\n",
    "    raise FileNotFoundError(f\"فایل {input_txt_path} پیدا نشد.\")\n",
    "\n",
    "# خواندن فایل متنی و ساخت دیتافریم\n",
    "with open(input_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "data = []\n",
    "for line in lines[1:]:  # رد کردن هدر\n",
    "    parts = line.strip().split(\"\\t\")\n",
    "    if len(parts) == 3:\n",
    "        data.append(parts)\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"name\", \"SVM_prediction\", \"DecisionTree_prediction\"])\n",
    "\n",
    "# استخراج برچسب واقعی از نام فایل (مثلاً 104_char2.png → 104)\n",
    "df[\"true_label\"] = df[\"name\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "# آماده‌سازی برای ارزیابی\n",
    "y_true = df[\"true_label\"]\n",
    "svm_pred = df[\"SVM_prediction\"]\n",
    "tree_pred = df[\"DecisionTree_prediction\"]\n",
    "\n",
    "# محاسبه معیارها\n",
    "svm_acc = accuracy_score(y_true, svm_pred)\n",
    "tree_acc = accuracy_score(y_true, tree_pred)\n",
    "svm_report = classification_report(y_true, svm_pred, zero_division=0)\n",
    "tree_report = classification_report(y_true, tree_pred, zero_division=0)\n",
    "svm_cm = confusion_matrix(y_true, svm_pred)\n",
    "tree_cm = confusion_matrix(y_true, tree_pred)\n",
    "\n",
    "# ساخت پوشه خروجی\n",
    "output_dir = \"output_phase5\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ذخیره خروجی‌ها در فایل متنی\n",
    "with open(os.path.join(output_dir, \"evaluation.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"SVM Accuracy: {svm_acc:.4f}\\n\")\n",
    "    f.write(f\"Decision Tree Accuracy: {tree_acc:.4f}\\n\\n\")\n",
    "\n",
    "    f.write(\"=== SVM Classification Report ===\\n\")\n",
    "    f.write(svm_report + \"\\n\")\n",
    "    f.write(\"=== SVM Confusion Matrix ===\\n\")\n",
    "    f.write(str(svm_cm) + \"\\n\\n\")\n",
    "\n",
    "    f.write(\"=== Decision Tree Classification Report ===\\n\")\n",
    "    f.write(tree_report + \"\\n\")\n",
    "    f.write(\"=== Decision Tree Confusion Matrix ===\\n\")\n",
    "    f.write(str(tree_cm) + \"\\n\")\n",
    "\n",
    "# --- چاپ در ترمینال ---\n",
    "print(\"✅ ارزیابی مدل‌ها تکمیل شد.\")\n",
    "print(f\"SVM Accuracy: {svm_acc:.4f}\")\n",
    "print(f\"Decision Tree Accuracy: {tree_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
