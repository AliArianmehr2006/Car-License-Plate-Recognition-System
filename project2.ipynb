{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8397fdda",
   "metadata": {},
   "source": [
    "# به نام خدا"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81215f",
   "metadata": {},
   "source": [
    "# فاز 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "259fd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49cd300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "پردازش تصاویر:   0%|          | 0/217 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "پردازش تصاویر: 100%|██████████| 217/217 [00:05<00:00, 36.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ پردازش فاز اول با موفقیت به پایان رسید. پلاک‌ها در پوشه 'output_phase1' ذخیره شدند.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# نسبت بزرگنمایی\n",
    "SCALE_X = 1280 / 224\n",
    "SCALE_Y = 1280 / 224\n",
    "\n",
    "def parse_annotation(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    plates = []\n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text\n",
    "        if name.lower() == 'vehicle plate':\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = int(int(bndbox.find('xmin').text) * SCALE_X)\n",
    "            ymin = int(int(bndbox.find('ymin').text) * SCALE_Y)\n",
    "            xmax = int(int(bndbox.find('xmax').text) * SCALE_X)\n",
    "            ymax = int(int(bndbox.find('ymax').text) * SCALE_Y)\n",
    "            plates.append((xmin, ymin, xmax, ymax))\n",
    "    \n",
    "    return plates\n",
    "\n",
    "def extract_plates(image_path, annotation_path, output_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"خطا در خواندن تصویر: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    plates = parse_annotation(annotation_path)\n",
    "    if not plates:\n",
    "        print(f\"هیچ پلاکی در فایل آنوتیشن یافت نشد: {annotation_path}\")\n",
    "        return\n",
    "    \n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    for i, (xmin, ymin, xmax, ymax) in enumerate(plates):\n",
    "        plate_img = image[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        output_file = os.path.join(output_path, f\"{base_name}.png\")\n",
    "        cv2.imwrite(output_file, plate_img)\n",
    "\n",
    "def process_dataset(base_dir, output_dir):\n",
    "    images_dir = os.path.join(base_dir, \"Vehicle Plates 1280x1280\", \"Vehicle Plates 1280x1280\")\n",
    "    annotations_dir = os.path.join(base_dir, \"Vehicle Plates annotations\", \"Vehicle Plates annotations\")\n",
    "    \n",
    "    if not os.path.exists(images_dir):\n",
    "        print(f\"پوشه تصاویر یافت نشد: {images_dir}\")\n",
    "        return\n",
    "    if not os.path.exists(annotations_dir):\n",
    "        print(f\"پوشه آنوتیشن‌ها یافت نشد: {annotations_dir}\")\n",
    "        return\n",
    "    \n",
    "    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for img_file in tqdm(image_files, desc=\"پردازش تصاویر\"):\n",
    "        base_name = os.path.splitext(img_file)[0]\n",
    "        image_path = os.path.join(images_dir, img_file)\n",
    "        annotation_path = os.path.join(annotations_dir, f\"{base_name}.xml\")\n",
    "        \n",
    "        if os.path.exists(annotation_path):\n",
    "            extract_plates(image_path, annotation_path, output_dir)\n",
    "        else:\n",
    "            print(f\"فایل آنوتیشن یافت نشد: {annotation_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"Plates2\"\n",
    "    output_dir = \"output_phase1\"\n",
    "    \n",
    "    process_dataset(base_dir, output_dir)\n",
    "    \n",
    "    print(f\"✅ پردازش فاز اول با موفقیت به پایان رسید. پلاک‌ها در پوشه '{output_dir}' ذخیره شدند.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c34b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "029a3767",
   "metadata": {},
   "source": [
    "# فاز 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f5693a",
   "metadata": {},
   "source": [
    "### درست کردن کجی و سیاه سفید کردن"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc24193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f24242e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ اصلاح زاویه با ترکیب minAreaRect + Hough انجام شد.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_folder = 'output_phase1'\n",
    "output_folder = 'output_phase2'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "def angle_from_min_area_rect(thresh):\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    largest = max(contours, key=cv2.contourArea)\n",
    "    rect = cv2.minAreaRect(largest)\n",
    "    angle = rect[-1]\n",
    "    if angle < -45:\n",
    "        angle += 90\n",
    "    elif angle > 45:\n",
    "        angle -= 90\n",
    "    return angle\n",
    "\n",
    "def angle_from_hough(gray):\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, minLineLength=30, maxLineGap=10)\n",
    "    if lines is None:\n",
    "        return None\n",
    "    angles = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "        if -45 < angle < 45:\n",
    "            angles.append(angle)\n",
    "    if not angles:\n",
    "        return None\n",
    "    return np.median(angles)\n",
    "\n",
    "def correct_skew_combined(gray_image, angle_threshold=3):\n",
    "    # Preprocess\n",
    "    _, thresh = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    thresh = 255 - thresh\n",
    "\n",
    "    # Step 1: try minAreaRect\n",
    "    angle = angle_from_min_area_rect(thresh)\n",
    "\n",
    "    # Step 2: fallback to HoughLines if angle too small or None\n",
    "    if angle is None or abs(angle) < angle_threshold:\n",
    "        angle = angle_from_hough(gray_image)\n",
    "\n",
    "    # اگر همچنان زاویه معنادار نبود، تصویر را برگردان\n",
    "    if angle is None or abs(angle) < angle_threshold:\n",
    "        return gray_image\n",
    "\n",
    "    # Rotate\n",
    "    (h, w) = gray_image.shape\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(gray_image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "# پردازش همه تصاویر\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "        path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        corrected = correct_skew_combined(gray)\n",
    "\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, corrected)\n",
    "\n",
    "print(\"✅ اصلاح زاویه با ترکیب minAreaRect + Hough انجام شد.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be0ea65",
   "metadata": {},
   "source": [
    "### کات دادن یک هشتم اول پلاک"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10779d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95457256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "پردازش تمام شد.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# مسیرهای ورودی و خروجی\n",
    "input_dir = 'output_phase2'\n",
    "output_dir = 'output_phase2.1'\n",
    "\n",
    "# ساخت پوشه خروجی اگر وجود نداشت\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# پردازش هر تصویر در پوشه ورودی\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tif')):\n",
    "        img_path = os.path.join(input_dir, filename)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # ابعاد تصویر\n",
    "        width, height = img.size\n",
    "\n",
    "        # عرض هر تکه\n",
    "        slice_width = width // 8\n",
    "\n",
    "        # برش تصویر: حذف تیکه اول (از x=0 تا x=slice_width)\n",
    "        # نگه داشتن بخش باقی‌مانده (از x=slice_width تا x=width)\n",
    "        cropped_img = img.crop((slice_width, 0, width, height))\n",
    "\n",
    "        # ذخیره تصویر خروجی\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cropped_img.save(output_path)\n",
    "\n",
    "print(\"پردازش تمام شد.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea3df5",
   "metadata": {},
   "source": [
    "### باینری کردن عکس ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa039ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd13ae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "پردازش پیشرفته و تبدیل به باینری با حفظ جزئیات انجام شد.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_folder = 'output_phase2.1'\n",
    "output_folder = 'output_phase2.2'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # 1. نویززدایی با فیلتر غیرمحلی (Non-local Means)\n",
    "        denoised = cv2.fastNlMeansDenoising(img, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "\n",
    "        # 2. افزایش کنتراست با CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        contrast_enhanced = clahe.apply(denoised)\n",
    "\n",
    "        # 3. نرم کردن با فیلتر گوسی\n",
    "        blurred = cv2.GaussianBlur(contrast_enhanced, (3, 3), 0)\n",
    "\n",
    "        # 4. آستانه‌گذاری تطبیقی برای باینری‌سازی\n",
    "        binary_img = cv2.adaptiveThreshold(\n",
    "            blurred,\n",
    "            255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY_INV,\n",
    "            11,  # اندازه بلوک\n",
    "            2    # مقدار ثابت\n",
    "        )\n",
    "\n",
    "        # 5. حذف نویزهای کوچک با مورفولوژی\n",
    "        kernel = np.ones((2, 2), np.uint8)\n",
    "        processed = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # 6. پر کردن حفره‌های داخل کاراکترها\n",
    "        h, w = processed.shape\n",
    "        flood_fill_mask = np.zeros((h + 2, w + 2), np.uint8)\n",
    "        im_floodfill = processed.copy()\n",
    "\n",
    "        # فیل کردن از یک نقطه‌ی مطمئن (گوشه‌ی تصویر)\n",
    "        cv2.floodFill(im_floodfill, flood_fill_mask, (0, 0), 255)\n",
    "\n",
    "        # یافتن حفره‌ها و پر کردن آن‌ها\n",
    "        holes = cv2.bitwise_not(im_floodfill) & processed\n",
    "        filled = processed | holes\n",
    "\n",
    "        # 7. معکوس کردن: متن سفید، پس‌زمینه سیاه\n",
    "        final_img = cv2.bitwise_not(filled)\n",
    "\n",
    "        # 8. ذخیره تصویر خروجی\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, final_img)\n",
    "\n",
    "print(\"پردازش پیشرفته و تبدیل به باینری با حفظ جزئیات انجام شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18e54b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "پردازش حرفه‌ای با حفظ حداکثر کیفیت انجام شد.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_folder = 'output_phase2.1'\n",
    "output_folder = 'output_phase2.2'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # 1. پیش‌پردازش اولیه با حفظ جزئیات\n",
    "        denoised = cv2.fastNlMeansDenoising(img, h=5, templateWindowSize=7, searchWindowSize=21)\n",
    "        \n",
    "        # 2. افزایش کنتراست هوشمند\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(12,12))\n",
    "        contrast_enhanced = clahe.apply(denoised)\n",
    "        \n",
    "        # 3. بهبود لبه‌ها با فیلتر ویژه\n",
    "        blurred = cv2.bilateralFilter(contrast_enhanced, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "        \n",
    "        # 4. روش ترکیبی آستانه‌گذاری\n",
    "        # مرحله اول: Adaptive Threshold\n",
    "        binary_adaptive = cv2.adaptiveThreshold(\n",
    "            blurred,\n",
    "            255,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY_INV,\n",
    "            blockSize=9,\n",
    "            C=2\n",
    "        )\n",
    "        \n",
    "        # مرحله دوم: Otsu Threshold\n",
    "        _, binary_otsu = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # مرحله سوم: ترکیب با وزن‌دهی\n",
    "        combined = cv2.addWeighted(binary_adaptive, 0.7, binary_otsu, 0.3, 0)\n",
    "        \n",
    "        # 5. بهبود نهایی با تکنیک Super-Resolution (اختیاری)\n",
    "        # اگر opencv با contrib نصب باشد:\n",
    "        # super_res = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "        # super_res.readModel('EDSR_x4.pb')\n",
    "        # super_res.setModel('edsr', 4)\n",
    "        # final_img = super_res.upsample(combined)\n",
    "        \n",
    "        # 6. ذخیره نتیجه\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, cv2.bitwise_not(combined))\n",
    "\n",
    "print(\"پردازش حرفه‌ای با حفظ حداکثر کیفیت انجام شد.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ef098",
   "metadata": {},
   "source": [
    "### در اوردن کاراکتر های هر عکس"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1aec5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e64f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 1.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 10.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 100.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 101.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 102.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 103.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 104.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 105.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 106.png: 2 کاراکتر نهایی ذخیره شد.\n",
      "✅ 107.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 108.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 109.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 11.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 110.png: 5 کاراکتر نهایی ذخیره شد.\n",
      "✅ 111.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 112.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 113.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 114.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 115.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 116.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 117.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 118.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 119.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 12.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 120.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 121.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 122.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 123.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 124.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 125.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 126.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 127.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 128.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 129.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 13.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 130.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 131.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 132.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 133.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 134.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 135.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 136.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 137.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 138.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 139.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 14.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 140.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 141.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 142.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 143.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 144.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 145.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 146.png: 0 کاراکتر نهایی ذخیره شد.\n",
      "✅ 147.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 148.png: 0 کاراکتر نهایی ذخیره شد.\n",
      "✅ 149.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 15.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 150.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 151.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 152.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 153.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 154.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 155.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 156.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 157.png: 4 کاراکتر نهایی ذخیره شد.\n",
      "✅ 158.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 159.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 16.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 160.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 161.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 162.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 163.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 164.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 165.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 166.png: 1 کاراکتر نهایی ذخیره شد.\n",
      "✅ 167.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 168.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 169.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 17.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 170.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 171.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 172.png: 2 کاراکتر نهایی ذخیره شد.\n",
      "✅ 173.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 174.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 175.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 176.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 177.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 178.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 179.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 18.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 180.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 181.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 182.png: 1 کاراکتر نهایی ذخیره شد.\n",
      "✅ 183.png: 0 کاراکتر نهایی ذخیره شد.\n",
      "✅ 184.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 185.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 186.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 187.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 188.png: 1 کاراکتر نهایی ذخیره شد.\n",
      "✅ 189.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 19.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 190.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 191.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 192.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 193.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 194.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 195.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 196.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 197.png: 0 کاراکتر نهایی ذخیره شد.\n",
      "✅ 198.png: 0 کاراکتر نهایی ذخیره شد.\n",
      "✅ 199.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 2.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 20.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 200.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 201.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 202.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 203.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 204.png: 1 کاراکتر نهایی ذخیره شد.\n",
      "✅ 205.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 206.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 207.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 208.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 209.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 21.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 210.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 211.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 212.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 213.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 214.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 215.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 216.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 217.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 22.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 23.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 24.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 25.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 26.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 27.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 28.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 29.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 3.png: 0 کاراکتر نهایی ذخیره شد.\n",
      "✅ 30.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 31.png: 6 کاراکتر نهایی ذخیره شد.\n",
      "✅ 32.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 33.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 34.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 35.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 36.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 37.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 38.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 39.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 4.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 40.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 41.png: 0 کاراکتر نهایی ذخیره شد.\n",
      "✅ 42.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 43.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 44.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 45.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 46.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 47.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 48.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 49.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 5.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 50.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 51.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 52.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 53.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 54.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 55.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 56.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 57.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 58.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 59.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 6.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 60.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 61.png: 0 کاراکتر نهایی ذخیره شد.\n",
      "✅ 62.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 63.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 64.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 65.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 66.png: 7 کاراکتر نهایی ذخیره شد.\n",
      "✅ 67.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 68.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 69.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 7.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 70.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 71.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 72.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 73.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 74.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 75.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 76.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 77.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 78.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 79.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 8.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 80.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 81.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 82.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 83.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 84.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 85.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 86.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 87.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 88.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 89.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 9.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 90.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 91.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 92.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 93.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 94.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 95.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 96.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 97.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 98.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "✅ 99.png: 8 کاراکتر نهایی ذخیره شد.\n",
      "🎯 پردازش کامل شد - دقیق و محدود به 8 کاراکتر.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_folder = \"output_phase2.2\"\n",
    "output_folder = \"output_phase2.3\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(input_folder, filename)\n",
    "    img_original = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img_original is None:\n",
    "        print(f\"⛔ نمی‌توان تصویر {filename} را خواند.\")\n",
    "        continue\n",
    "\n",
    "    # بزرگنمایی ×3\n",
    "    scale = 3\n",
    "    img_highres = cv2.resize(img_original, (img_original.shape[1]*scale, img_original.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # صاف‌سازی و باینری کردن\n",
    "    img_blur = cv2.GaussianBlur(img_highres, (3, 3), 0)\n",
    "    img_bin = cv2.adaptiveThreshold(\n",
    "        img_blur, 255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        15, 8\n",
    "    )\n",
    "\n",
    "    # حذف نویزهای کوچک\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    img_bin = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # پیدا کردن کانتور\n",
    "    contours, _ = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # فقط خارجی\n",
    "\n",
    "    # فیلتر بر اساس ابعاد نسبی (هوشمندانه‌تر)\n",
    "    boxes = []\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        area = cv2.contourArea(c)\n",
    "        if w < 10 or h < 20:\n",
    "            continue\n",
    "        if w > img_highres.shape[1] * 0.5 or h > img_highres.shape[0] * 0.9:\n",
    "            continue\n",
    "        if area < 100:\n",
    "            continue\n",
    "        boxes.append((x, y, w, h))\n",
    "\n",
    "    # 🔧 اگر خیلی کانتور داریم، فقط 8 تا از مناسب‌ترین‌ها رو بگیریم\n",
    "    if len(boxes) > 8:\n",
    "        boxes = sorted(boxes, key=lambda b: b[2]*b[3], reverse=True)  # بر اساس مساحت\n",
    "        boxes = boxes[:8]\n",
    "\n",
    "    # 🔧 مرتب‌سازی از چپ به راست\n",
    "    boxes = sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "    count = 0\n",
    "    pad = 6\n",
    "    for i, (x, y, w, h) in enumerate(boxes):\n",
    "        x_new = max(x - pad, 0)\n",
    "        y_new = max(y - pad, 0)\n",
    "        w_new = min(w + 2 * pad, img_highres.shape[1] - x_new)\n",
    "        h_new = min(h + 2 * pad, img_highres.shape[0] - y_new)\n",
    "\n",
    "        char_img = img_highres[y_new:y_new + h_new, x_new:x_new + w_new]\n",
    "\n",
    "        # تغییر اندازه و شارپ کردن\n",
    "        char_img_resized = cv2.resize(char_img, (64, 128), interpolation=cv2.INTER_CUBIC)\n",
    "        kernel_sharp = np.array([[0, -1, 0],\n",
    "                                 [-1, 5, -1],\n",
    "                                 [0, -1, 0]])\n",
    "        char_img_resized = cv2.filter2D(char_img_resized, -1, kernel_sharp)\n",
    "\n",
    "        out_name = f\"{os.path.splitext(filename)[0]}_char{count + 1}.png\"\n",
    "        cv2.imwrite(os.path.join(output_folder, out_name), char_img_resized)\n",
    "        count += 1\n",
    "\n",
    "    print(f\"✅ {filename}: {count} کاراکتر نهایی ذخیره شد.\")\n",
    "\n",
    "print(\"🎯 پردازش کامل شد - دقیق و محدود به 8 کاراکتر.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f62bb93",
   "metadata": {},
   "source": [
    "### تنظیم سایز تصاویر"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "477626e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0d300c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1612/1612 [00:01<00:00, 1402.84it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# مسیرها\n",
    "input_dir = 'output_phase2.3'\n",
    "output_dir = 'output_phase2.4'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def clean_and_center_image(img, size=(28, 28)):\n",
    "    # تبدیل به خاکستری اگر رنگی بود\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # باینری کردن (متن سیاه، زمینه سفید)\n",
    "    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # حذف نویز با Morphology\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    clean = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "    # پیدا کردن بزرگ‌ترین کانتور (کاراکتر اصلی)\n",
    "    contours, _ = cv2.findContours(clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return np.ones(size, dtype=np.uint8) * 255  # برگرد تصویر سفید خالی\n",
    "\n",
    "    # انتخاب بزرگ‌ترین کانتور\n",
    "    main_contour = max(contours, key=cv2.contourArea)\n",
    "    mask = np.zeros_like(clean)\n",
    "    cv2.drawContours(mask, [main_contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    # فقط کاراکتر اصلی نگه داشته بشه\n",
    "    isolated = cv2.bitwise_and(clean, mask)\n",
    "\n",
    "    # کراپ به اطراف کاراکتر\n",
    "    x, y, w, h = cv2.boundingRect(main_contour)\n",
    "    char_img = isolated[y:y+h, x:x+w]\n",
    "\n",
    "    # ریسایز با حفظ نسبت\n",
    "    h_new, w_new = char_img.shape\n",
    "    scale = min((size[0] - 4) / h_new, (size[1] - 4) / w_new)\n",
    "    char_resized = cv2.resize(char_img, (int(w_new * scale), int(h_new * scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # قرار دادن وسط تصویر سفید\n",
    "    final_img = np.ones(size, dtype=np.uint8) * 255\n",
    "    h_final, w_final = char_resized.shape\n",
    "    y_offset = (size[0] - h_final) // 2\n",
    "    x_offset = (size[1] - w_final) // 2\n",
    "    final_img[y_offset:y_offset+h_final, x_offset:x_offset+w_final] = 255 - char_resized  # برعکسش کنیم چون اینورت شده بود\n",
    "\n",
    "    return final_img\n",
    "\n",
    "# پردازش تصاویر\n",
    "for filename in tqdm(os.listdir(input_dir)):\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    img = cv2.imread(input_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    cleaned_img = clean_and_center_image(img)\n",
    "    cv2.imwrite(output_path, cleaned_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3321b95",
   "metadata": {},
   "source": [
    "# فاز 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ac998",
   "metadata": {},
   "source": [
    "### آماده سازی داده ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0435894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "adbf1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "input_dir = 'alpha'\n",
    "output_dir = 'output_phase3'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def crop_white_borders(image):\n",
    "    \"\"\"برش دادن نواحی سفید اطراف تصویر\"\"\"\n",
    "    bg = Image.new(image.mode, image.size, (255, 255, 255))  # زمینه سفید\n",
    "    diff = ImageChops.difference(image, bg)\n",
    "    bbox = diff.getbbox()\n",
    "    return image.crop(bbox) if bbox else image\n",
    "\n",
    "def paste_on_white_canvas(image, size=(28, 28)):\n",
    "    \"\"\"قرار دادن تصویر در بوم سفید و وسط‌چین کردن آن\"\"\"\n",
    "    canvas = Image.new(\"RGB\", size, (255, 255, 255))  # ← بوم سفید\n",
    "    img_w, img_h = image.size\n",
    "    scale = min(size[0] / img_w, size[1] / img_h)\n",
    "    new_size = (int(img_w * scale), int(img_h * scale))\n",
    "    image = image.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "    paste_x = (size[0] - new_size[0]) // 2\n",
    "    paste_y = (size[1] - new_size[1]) // 2\n",
    "    canvas.paste(image, (paste_x, paste_y))\n",
    "    return canvas\n",
    "\n",
    "for folder_name in os.listdir(input_dir):\n",
    "    input_folder_path = os.path.join(input_dir, folder_name)\n",
    "    \n",
    "    if os.path.isdir(input_folder_path):\n",
    "        output_folder_path = os.path.join(output_dir, folder_name)\n",
    "        os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "        for img_name in os.listdir(input_folder_path):\n",
    "            input_img_path = os.path.join(input_folder_path, img_name)\n",
    "            output_img_path = os.path.join(output_folder_path, img_name)\n",
    "\n",
    "            try:\n",
    "                with Image.open(input_img_path) as img:\n",
    "                    img = img.convert(\"RGB\")\n",
    "                    cropped_img = crop_white_borders(img)\n",
    "                    final_img = paste_on_white_canvas(cropped_img, size=(28, 28))\n",
    "                    final_img.save(output_img_path)\n",
    "            except Exception as e:\n",
    "                print(f\"خطا در پردازش عکس {input_img_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c4f97",
   "metadata": {},
   "source": [
    "### اموزش مدل"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8eb049cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d8eb6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 در حال پردازش تصاویر...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:02<00:00, 17.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 تعداد کل نمونه‌ها (با Augmentation): 7798\n",
      "⚙️ در حال اعمال PCA...\n",
      "\n",
      "🎓 آموزش SVM...\n",
      "🎯 دقت SVM روی داده‌های آموزش: 0.98\n",
      "🎯 دقت SVM روی داده‌های تست: 0.96\n",
      "\n",
      "🎓 آموزش درخت تصمیم (با جلوگیری از Overfitting)...\n",
      "🌳 دقت درخت تصمیم روی داده‌های آموزش: 0.84\n",
      "🌳 دقت درخت تصمیم روی داده‌های تست: 0.76\n",
      "\n",
      "🔍 جستجوی بهترین تنظیمات Random Forest با GridSearch...\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "🌲 بهترین پارامترهای Random Forest: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "🌲 دقت Random Forest روی داده‌های آموزش: 1.00\n",
      "🌲 دقت Random Forest روی داده‌های تست: 0.93\n",
      "\n",
      "✅ مدل‌ها و PCA در مسیر output_phase3.1 ذخیره شدند.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# مسیرها\n",
    "input_dir = 'output_phase3'                 # داده‌های آموزشی\n",
    "output_dir = 'output_phase3.1'              # ذخیره مدل‌ها\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# پارامترهای HOG\n",
    "image_size = (28, 28)\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# بارگذاری برچسب‌ها از نام پوشه‌ها\n",
    "label_names = sorted(os.listdir(input_dir))\n",
    "label_map = {name: idx for idx, name in enumerate(label_names)}\n",
    "\n",
    "def preprocess_image(img):\n",
    "    _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    x, y_, w, h = cv2.boundingRect(binary)\n",
    "    cropped = binary[y_:y_+h, x:x+w]\n",
    "    resized = cv2.resize(cropped, image_size)\n",
    "    return resized\n",
    "\n",
    "def augment_image(img):\n",
    "    rows, cols = img.shape\n",
    "    angle = np.random.uniform(-10, 10)\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1.0)\n",
    "    return cv2.warpAffine(img, M, (cols, rows), borderValue=255)\n",
    "\n",
    "print(\"🚀 در حال پردازش تصاویر...\")\n",
    "\n",
    "for label_name in tqdm(label_names):\n",
    "    folder_path = os.path.join(input_dir, label_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            pre_img = preprocess_image(img)\n",
    "\n",
    "            # ویژگی اصلی\n",
    "            features = hog(pre_img,\n",
    "                           orientations=orientations,\n",
    "                           pixels_per_cell=pixels_per_cell,\n",
    "                           cells_per_block=cells_per_block,\n",
    "                           block_norm='L2-Hys',\n",
    "                           visualize=False)\n",
    "            X.append(features)\n",
    "            y.append(label_map[label_name])\n",
    "\n",
    "            # نسخه چرخش‌دار\n",
    "            aug_img = augment_image(pre_img)\n",
    "            features_aug = hog(aug_img,\n",
    "                               orientations=orientations,\n",
    "                               pixels_per_cell=pixels_per_cell,\n",
    "                               cells_per_block=cells_per_block,\n",
    "                               block_norm='L2-Hys',\n",
    "                               visualize=False)\n",
    "            X.append(features_aug)\n",
    "            y.append(label_map[label_name])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ خطا در پردازش {img_path}: {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"\\n📊 تعداد کل نمونه‌ها (با Augmentation): {X.shape[0]}\")\n",
    "\n",
    "# کاهش بعد با PCA\n",
    "print(\"⚙️ در حال اعمال PCA...\")\n",
    "pca = PCA(n_components=50)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# تقسیم آموزش/تست\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# آموزش SVM\n",
    "print(\"\\n🎓 آموزش SVM...\")\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# دقت SVM\n",
    "svm_train_acc = accuracy_score(y_train, svm_model.predict(X_train))\n",
    "svm_test_acc = accuracy_score(y_test, svm_model.predict(X_test))\n",
    "print(f\"🎯 دقت SVM روی داده‌های آموزش: {svm_train_acc:.2f}\")\n",
    "print(f\"🎯 دقت SVM روی داده‌های تست: {svm_test_acc:.2f}\")\n",
    "\n",
    "# آموزش درخت تصمیم با کنترل Overfitting با pruning و محدودیت‌های بهینه\n",
    "print(\"\\n🎓 آموزش درخت تصمیم (با جلوگیری از Overfitting)...\")\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    ccp_alpha=0.001,  # pruning\n",
    "    random_state=42\n",
    ")\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "dt_train_acc = accuracy_score(y_train, dt_model.predict(X_train))\n",
    "dt_test_acc = accuracy_score(y_test, dt_model.predict(X_test))\n",
    "print(f\"🌳 دقت درخت تصمیم روی داده‌های آموزش: {dt_train_acc:.2f}\")\n",
    "print(f\"🌳 دقت درخت تصمیم روی داده‌های تست: {dt_test_acc:.2f}\")\n",
    "\n",
    "# استفاده از GridSearchCV برای تنظیم Random Forest\n",
    "print(\"\\n🔍 جستجوی بهترین تنظیمات Random Forest با GridSearch...\")\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "rf_model = grid_search.best_estimator_\n",
    "\n",
    "# دقت Random Forest\n",
    "rf_train_acc = accuracy_score(y_train, rf_model.predict(X_train))\n",
    "rf_test_acc = accuracy_score(y_test, rf_model.predict(X_test))\n",
    "print(f\"🌲 بهترین پارامترهای Random Forest: {grid_search.best_params_}\")\n",
    "print(f\"🌲 دقت Random Forest روی داده‌های آموزش: {rf_train_acc:.2f}\")\n",
    "print(f\"🌲 دقت Random Forest روی داده‌های تست: {rf_test_acc:.2f}\")\n",
    "\n",
    "# ذخیره مدل‌ها\n",
    "joblib.dump(svm_model, os.path.join(output_dir, 'svm_model.joblib'))\n",
    "joblib.dump(dt_model, os.path.join(output_dir, 'decision_tree_model.joblib'))\n",
    "joblib.dump(rf_model, os.path.join(output_dir, 'random_forest_model.joblib'))\n",
    "joblib.dump(pca, os.path.join(output_dir, 'pca_transform.joblib'))\n",
    "\n",
    "print(f\"\\n✅ مدل‌ها و PCA در مسیر {output_dir} ذخیره شدند.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f054a3",
   "metadata": {},
   "source": [
    "# فاز 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e8416e",
   "metadata": {},
   "source": [
    "### نام دادن کاراکتر ها با مدل های خودمون"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cbadd9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "import joblib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da6a8193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "در حال پردازش تصاویر برای پیش‌بینی برچسب‌ها...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1612/1612 [00:08<00:00, 180.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ پیش‌بینی‌های SVM در فایل output_phase4\\svm_predictions.txt ذخیره شد.\n",
      "✅ پیش‌بینی‌های Decision Tree در فایل output_phase4\\decision_tree_predictions.txt ذخیره شد.\n",
      "✅ پیش‌بینی‌های Random Forest در فایل output_phase4\\random_forest_predictions.txt ذخیره شد.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# مسیرها\n",
    "input_dir = 'output_phase2.4'\n",
    "model_dir = 'output_phase3.1'\n",
    "output_dir = 'output_phase4'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# بارگذاری مدل‌ها و PCA\n",
    "svm_model = joblib.load(os.path.join(model_dir, 'svm_model.joblib'))\n",
    "dt_model = joblib.load(os.path.join(model_dir, 'decision_tree_model.joblib'))\n",
    "rf_model = joblib.load(os.path.join(model_dir, 'random_forest_model.joblib'))  # اضافه شد\n",
    "pca = joblib.load(os.path.join(model_dir, 'pca_transform.joblib'))\n",
    "\n",
    "# پارامترهای HOG\n",
    "image_size = (28, 28)\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "\n",
    "# بارگذاری نام برچسب‌ها\n",
    "label_names = sorted(os.listdir('output_phase3'))\n",
    "label_map = {name: idx for idx, name in enumerate(label_names)}\n",
    "inv_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "def preprocess_image(img):\n",
    "    _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    x, y_, w, h = cv2.boundingRect(binary)\n",
    "    cropped = binary[y_:y_+h, x:x+w]\n",
    "    resized = cv2.resize(cropped, image_size)\n",
    "    return resized\n",
    "\n",
    "# لیست‌های نتایج برای هر مدل\n",
    "svm_results = []\n",
    "dt_results = []\n",
    "rf_results = []  # اضافه شد\n",
    "\n",
    "print(\"در حال پردازش تصاویر برای پیش‌بینی برچسب‌ها...\")\n",
    "\n",
    "for img_name in tqdm(os.listdir(input_dir)):\n",
    "    img_path = os.path.join(input_dir, img_name)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"⚠️ نمی‌توان تصویر {img_name} را خواند.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        pre_img = preprocess_image(img)\n",
    "        features = hog(pre_img,\n",
    "                       orientations=orientations,\n",
    "                       pixels_per_cell=pixels_per_cell,\n",
    "                       cells_per_block=cells_per_block,\n",
    "                       block_norm='L2-Hys',\n",
    "                       visualize=False)\n",
    "        features_pca = pca.transform([features])\n",
    "\n",
    "        svm_pred = svm_model.predict(features_pca)[0]\n",
    "        dt_pred = dt_model.predict(features_pca)[0]\n",
    "        rf_pred = rf_model.predict(features_pca)[0]  # اضافه شد\n",
    "\n",
    "        svm_label = inv_label_map.get(svm_pred, \"Unknown\")\n",
    "        dt_label = inv_label_map.get(dt_pred, \"Unknown\")\n",
    "        rf_label = inv_label_map.get(rf_pred, \"Unknown\")  # اضافه شد\n",
    "\n",
    "        svm_results.append(f\"{img_name}\\t{svm_label}\")\n",
    "        dt_results.append(f\"{img_name}\\t{dt_label}\")\n",
    "        rf_results.append(f\"{img_name}\\t{rf_label}\")  # اضافه شد\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ خطا در پردازش {img_name}: {e}\")\n",
    "\n",
    "# ذخیره نتایج جداگانه\n",
    "svm_output_file = os.path.join(output_dir, 'svm_predictions.txt')\n",
    "dt_output_file = os.path.join(output_dir, 'decision_tree_predictions.txt')\n",
    "rf_output_file = os.path.join(output_dir, 'random_forest_predictions.txt')  # اضافه شد\n",
    "\n",
    "with open(svm_output_file, 'w', encoding='utf-8') as f:\n",
    "    for line in svm_results:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "with open(dt_output_file, 'w', encoding='utf-8') as f:\n",
    "    for line in dt_results:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "with open(rf_output_file, 'w', encoding='utf-8') as f:  # اضافه شد\n",
    "    for line in rf_results:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print(f\"\\n✅ پیش‌بینی‌های SVM در فایل {svm_output_file} ذخیره شد.\")\n",
    "print(f\"✅ پیش‌بینی‌های Decision Tree در فایل {dt_output_file} ذخیره شد.\")\n",
    "print(f\"✅ پیش‌بینی‌های Random Forest در فایل {rf_output_file} ذخیره شد.\")  # اضافه شد\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e974c",
   "metadata": {},
   "source": [
    "### نام دادن به تصاویر"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f353ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ad1c347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تمام شد. تصاویر دسته‌بندی و نام‌گذاری شدند.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# مسیرها\n",
    "images_dir = \"output_phase2.4\"\n",
    "names_dir = \"output_phase4\"\n",
    "output_dir = \"output_phase4.1\"\n",
    "\n",
    "# ساختن پوشه خروجی\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# خواندن تمام فایل‌های txt در پوشه output_phase4\n",
    "for txt_file in os.listdir(names_dir):\n",
    "    if txt_file.endswith(\".txt\"):\n",
    "        model_name = os.path.splitext(txt_file)[0]\n",
    "        model_output_path = os.path.join(output_dir, model_name)\n",
    "        os.makedirs(model_output_path, exist_ok=True)\n",
    "\n",
    "        # مسیر فایل txt\n",
    "        txt_path = os.path.join(names_dir, txt_file)\n",
    "\n",
    "        # خواندن نام‌ فایل‌ها از txt + پاکسازی\n",
    "        with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = [line.strip().replace('\\t', '').replace('/', '_').replace('\\\\', '_') for line in f if line.strip()]\n",
    "\n",
    "        # پیدا کردن تصاویر به همان ترتیب در پوشه تصاویر\n",
    "        image_files = sorted(os.listdir(images_dir))  # اگر لازم شد، فیلتر روی فرمت بگذار\n",
    "        for i, new_name in enumerate(lines):\n",
    "            if i >= len(image_files):\n",
    "                print(f\"تعداد تصاویر کافی نیست برای {txt_file}\")\n",
    "                break\n",
    "\n",
    "            original_image_path = os.path.join(images_dir, image_files[i])\n",
    "            extension = os.path.splitext(image_files[i])[1]\n",
    "            clean_name = new_name.strip().replace(\" \", \"_\").replace(\":\", \"-\")  # بیشتر پاکسازی اگر لازم بود\n",
    "            new_image_name = f\"{clean_name}{extension}\"\n",
    "            new_image_path = os.path.join(model_output_path, new_image_name)\n",
    "\n",
    "            try:\n",
    "                shutil.copy(original_image_path, new_image_path)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ خطا در کپی {original_image_path} به {new_image_path}: {e}\")\n",
    "\n",
    "print(\"✅ تمام شد. تصاویر دسته‌بندی و نام‌گذاری شدند.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b28ec",
   "metadata": {},
   "source": [
    "### نمایش کاراکتر های پلاک به در یک خط"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cb3ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27de5ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "در حال پردازش تصاویر برای پیش‌بینی برچسب‌ها...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1612/1612 [00:06<00:00, 264.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ فایل‌های زیر ساخته شدند:\n",
      "📄 output_phase4.2\\svm_predictions.txt\n",
      "📄 output_phase4.2\\dt_predictions.txt\n",
      "📄 output_phase4.2\\random_forest_predictions.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# مسیرها\n",
    "input_dir = 'output_phase2.4'     # تصاویر کاراکترها برای تشخیص\n",
    "model_dir = 'output_phase3.1'     # مدل‌ها و PCA از فاز 3\n",
    "output_dir = 'output_phase4.2'      # خروجی فاز 4\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# بارگذاری مدل‌ها و PCA\n",
    "svm_model = joblib.load(os.path.join(model_dir, 'svm_model.joblib'))\n",
    "dt_model = joblib.load(os.path.join(model_dir, 'decision_tree_model.joblib'))\n",
    "rf_model = joblib.load(os.path.join(model_dir, 'random_forest_model.joblib'))  # اضافه شده\n",
    "pca = joblib.load(os.path.join(model_dir, 'pca_transform.joblib'))\n",
    "\n",
    "# پارامترهای HOG\n",
    "image_size = (28, 28)\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "\n",
    "# بارگذاری نام برچسب‌ها\n",
    "label_names = sorted(os.listdir('output_phase3'))\n",
    "label_map = {name: idx for idx, name in enumerate(label_names)}\n",
    "inv_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "def preprocess_image(img):\n",
    "    _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    x, y_, w, h = cv2.boundingRect(binary)\n",
    "    cropped = binary[y_:y_+h, x:x+w]\n",
    "    resized = cv2.resize(cropped, image_size)\n",
    "    return resized\n",
    "\n",
    "# برای ذخیره پیش‌بینی‌ها\n",
    "svm_results = defaultdict(list)\n",
    "dt_results = defaultdict(list)\n",
    "rf_results = defaultdict(list)  # اضافه شده\n",
    "\n",
    "print(\"در حال پردازش تصاویر برای پیش‌بینی برچسب‌ها...\")\n",
    "\n",
    "# مرتب‌سازی فایل‌ها برای ترتیب صحیح کاراکترها\n",
    "image_files = sorted(os.listdir(input_dir))\n",
    "\n",
    "for img_name in tqdm(image_files):\n",
    "    img_path = os.path.join(input_dir, img_name)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"⚠️ نمی‌توان تصویر {img_name} را خواند.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        plate_id = img_name.split('_')[0]  # مثل 101 از \"101_char5.png\"\n",
    "        pre_img = preprocess_image(img)\n",
    "        features = hog(pre_img,\n",
    "                       orientations=orientations,\n",
    "                       pixels_per_cell=pixels_per_cell,\n",
    "                       cells_per_block=cells_per_block,\n",
    "                       block_norm='L2-Hys',\n",
    "                       visualize=False)\n",
    "        features_pca = pca.transform([features])\n",
    "\n",
    "        svm_pred = svm_model.predict(features_pca)[0]\n",
    "        dt_pred = dt_model.predict(features_pca)[0]\n",
    "        rf_pred = rf_model.predict(features_pca)[0]  # اضافه شده\n",
    "\n",
    "        svm_label = inv_label_map.get(svm_pred, \"Unknown\")\n",
    "        dt_label = inv_label_map.get(dt_pred, \"Unknown\")\n",
    "        rf_label = inv_label_map.get(rf_pred, \"Unknown\")  # اضافه شده\n",
    "\n",
    "        svm_results[plate_id].append(svm_label)\n",
    "        dt_results[plate_id].append(dt_label)\n",
    "        rf_results[plate_id].append(rf_label)  # اضافه شده\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ خطا در پردازش {img_name}: {e}\")\n",
    "\n",
    "# نوشتن خروجی‌ها\n",
    "svm_output_path = os.path.join(output_dir, 'svm_predictions.txt')\n",
    "dt_output_path = os.path.join(output_dir, 'dt_predictions.txt')\n",
    "rf_output_path = os.path.join(output_dir, 'random_forest_predictions.txt')  # اضافه شده\n",
    "\n",
    "with open(svm_output_path, 'w', encoding='utf-8') as f_svm, \\\n",
    "     open(dt_output_path, 'w', encoding='utf-8') as f_dt, \\\n",
    "     open(rf_output_path, 'w', encoding='utf-8') as f_rf:  # اضافه شده\n",
    "    f_svm.write(\"name,plate\\n\")\n",
    "    f_dt.write(\"name,plate\\n\")\n",
    "    f_rf.write(\"name,plate\\n\")  # اضافه شده\n",
    "\n",
    "    for plate_id in sorted(svm_results.keys(), key=lambda x: int(x)):\n",
    "        svm_line = ','.join([plate_id] + svm_results[plate_id])\n",
    "        dt_line = ','.join([plate_id] + dt_results[plate_id])\n",
    "        rf_line = ','.join([plate_id] + rf_results[plate_id])  # اضافه شده\n",
    "        f_svm.write(svm_line + '\\n')\n",
    "        f_dt.write(dt_line + '\\n')\n",
    "        f_rf.write(rf_line + '\\n')  # اضافه شده\n",
    "\n",
    "print(\"\\n✅ فایل‌های زیر ساخته شدند:\")\n",
    "print(\"📄\", svm_output_path)\n",
    "print(\"📄\", dt_output_path)\n",
    "print(\"📄\", rf_output_path)  # اضافه شده\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d3f7cd",
   "metadata": {},
   "source": [
    "### تصحیح نام کاراکتر ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd9427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be8b14ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ فایل svm_predictions.txt پردازش و ذخیره شد در output_phase4.3\\svm_predictions.txt\n",
      "✅ فایل random_forest_predictions.txt پردازش و ذخیره شد در output_phase4.3\\random_forest_predictions.txt\n",
      "✅ فایل dt_predictions.txt پردازش و ذخیره شد در output_phase4.3\\dt_predictions.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dir = \"output_phase4.2\"\n",
    "output_dir = \"output_phase4.3\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model_files = {\n",
    "    \"svm\": \"svm_predictions.txt\",\n",
    "    \"random_forest\": \"random_forest_predictions.txt\",\n",
    "    \"dt\": \"dt_predictions.txt\"\n",
    "}\n",
    "\n",
    "def clean_labels_from_file(input_path, output_path):\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as fin, open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        header = fin.readline()\n",
    "        fout.write(header)  # نوشتن header به فایل خروجی\n",
    "\n",
    "        for line in fin:\n",
    "            parts = line.strip().split(\",\")\n",
    "            name = parts[0]\n",
    "            labels = parts[1:]\n",
    "            cleaned_labels = []\n",
    "            for label in labels:\n",
    "                if '-' in label:\n",
    "                    cleaned_labels.append(label.split('-', 1)[1])\n",
    "                else:\n",
    "                    cleaned_labels.append(label)\n",
    "            fout.write(name + \",\" + \",\".join(cleaned_labels) + \"\\n\")\n",
    "\n",
    "for model_name, filename in model_files.items():\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    if os.path.exists(input_path):\n",
    "        clean_labels_from_file(input_path, output_path)\n",
    "        print(f\"✅ فایل {filename} پردازش و ذخیره شد در {output_path}\")\n",
    "    else:\n",
    "        print(f\"⚠️ فایل {filename} در مسیر {input_dir} یافت نشد!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be37007",
   "metadata": {},
   "source": [
    "# فاز 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c287e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae9afc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 8 samples after filtering.\n",
      "\n",
      "🔍 SVM Evaluation:\n",
      "  ✅ Accuracy : 23.17%\n",
      "  🎯 Precision: 7.65%\n",
      "  🔁 Recall   : 6.97%\n",
      "Decision Tree: 6 samples after filtering.\n",
      "\n",
      "🔍 DT Evaluation:\n",
      "  ✅ Accuracy : 12.66%\n",
      "  🎯 Precision: 8.69%\n",
      "  🔁 Recall   : 7.44%\n",
      "Random Forest: 9 samples after filtering.\n",
      "\n",
      "🔍 RANDOM_FOREST Evaluation:\n",
      "  ✅ Accuracy : 7.78%\n",
      "  🎯 Precision: 1.79%\n",
      "  🔁 Recall   : 1.39%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# مسیر فایل‌ها\n",
    "svm_pred_path = \"output_phase4.3/svm_predictions.txt\"\n",
    "dt_pred_path = \"output_phase4.3/dt_predictions.txt\"\n",
    "rf_pred_path = \"output_phase4.3/random_forest_predictions.txt\"\n",
    "label_path = \"Plates2/plate_labels.txt\"\n",
    "output_dir = \"output_phase5\"\n",
    "\n",
    "# ایجاد پوشه خروجی در صورت عدم وجود\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# تابع خواندن فایل‌ها\n",
    "def read_labels(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        return [line.strip() for line in f.readlines()]\n",
    "\n",
    "# خواندن داده‌ها\n",
    "y_true = read_labels(label_path)\n",
    "y_pred_svm = read_labels(svm_pred_path)\n",
    "y_pred_dt = read_labels(dt_pred_path)\n",
    "y_pred_rf = read_labels(rf_pred_path)\n",
    "\n",
    "# فیلتر پلاک‌هایی که طول کاراکترها برابر است\n",
    "def filter_matching_length(true_labels, pred_labels):\n",
    "    filtered_true = []\n",
    "    filtered_pred = []\n",
    "    for t, p in zip(true_labels, pred_labels):\n",
    "        if len(t) == len(p):\n",
    "            filtered_true.append(t)\n",
    "            filtered_pred.append(p)\n",
    "    return filtered_true, filtered_pred\n",
    "\n",
    "# تبدیل لیست به کاراکترهای جداگانه\n",
    "def flatten(chars_list):\n",
    "    return [char for plate in chars_list for char in plate]\n",
    "\n",
    "# ارزیابی مدل\n",
    "def evaluate_model(y_true_chars, y_pred_chars, model_name):\n",
    "    acc = accuracy_score(y_true_chars, y_pred_chars)\n",
    "    prec = precision_score(y_true_chars, y_pred_chars, average='macro', zero_division=0)\n",
    "    rec = recall_score(y_true_chars, y_pred_chars, average='macro', zero_division=0)\n",
    "    cm = confusion_matrix(y_true_chars, y_pred_chars)\n",
    "\n",
    "    # ذخیره فایل متریک‌ها\n",
    "    with open(f\"{output_dir}/{model_name}_metrics.txt\", \"w\") as f:\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
    "        f.write(f\"Precision: {prec:.4f}\\n\")\n",
    "        f.write(f\"Recall: {rec:.4f}\\n\")\n",
    "\n",
    "    # رسم confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "    plt.title(f\"Confusion Matrix - {model_name.upper()}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/{model_name}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # چاپ درصدها در ترمینال\n",
    "    print(f\"\\n🔍 {model_name.upper()} Evaluation:\")\n",
    "    print(f\"  ✅ Accuracy : {acc * 100:.2f}%\")\n",
    "    print(f\"  🎯 Precision: {prec * 100:.2f}%\")\n",
    "    print(f\"  🔁 Recall   : {rec * 100:.2f}%\")\n",
    "\n",
    "# ===========================\n",
    "# ارزیابی SVM\n",
    "y_true_svm, y_pred_svm_filtered = filter_matching_length(y_true, y_pred_svm)\n",
    "print(f\"SVM: {len(y_true_svm)} samples after filtering.\")\n",
    "y_true_chars_svm = flatten(y_true_svm)\n",
    "y_pred_svm_chars = flatten(y_pred_svm_filtered)\n",
    "\n",
    "if y_true_chars_svm and y_pred_svm_chars:\n",
    "    evaluate_model(y_true_chars_svm, y_pred_svm_chars, \"svm\")\n",
    "else:\n",
    "    print(\"⚠️ SVM: No valid data after filtering for matching lengths.\")\n",
    "\n",
    "# ارزیابی Decision Tree\n",
    "y_true_dt, y_pred_dt_filtered = filter_matching_length(y_true, y_pred_dt)\n",
    "print(f\"Decision Tree: {len(y_true_dt)} samples after filtering.\")\n",
    "y_true_chars_dt = flatten(y_true_dt)\n",
    "y_pred_dt_chars = flatten(y_pred_dt_filtered)\n",
    "\n",
    "if y_true_chars_dt and y_pred_dt_chars:\n",
    "    evaluate_model(y_true_chars_dt, y_pred_dt_chars, \"dt\")\n",
    "else:\n",
    "    print(\"⚠️ Decision Tree: No valid data after filtering for matching lengths.\")\n",
    "\n",
    "# ارزیابی Random Forest\n",
    "y_true_rf, y_pred_rf_filtered = filter_matching_length(y_true, y_pred_rf)\n",
    "print(f\"Random Forest: {len(y_true_rf)} samples after filtering.\")\n",
    "y_true_chars_rf = flatten(y_true_rf)\n",
    "y_pred_rf_chars = flatten(y_pred_rf_filtered)\n",
    "\n",
    "if y_true_chars_rf and y_pred_rf_chars:\n",
    "    evaluate_model(y_true_chars_rf, y_pred_rf_chars, \"random_forest\")\n",
    "else:\n",
    "    print(\"⚠️ Random Forest: No valid data after filtering for matching lengths.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
